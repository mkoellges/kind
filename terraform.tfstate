{
  "version": 4,
  "terraform_version": "1.5.7",
  "serial": 90,
  "lineage": "45f8d957-85f5-6335-3114-b364b45e42ba",
  "outputs": {
    "cluster_name": {
      "value": "dev-1",
      "type": "string"
    },
    "kubeconfig_path": {
      "value": "~/.kube/config",
      "type": "string"
    },
    "kubernetes_version": {
      "value": "kindest/node:v1.29.0",
      "type": "string"
    }
  },
  "resources": [
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "argocd",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 1,
          "attributes": {
            "atomic": false,
            "chart": "argo-cd",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": false,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "argocd",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "v2.13.1",
                "chart": "argo-cd",
                "name": "argocd",
                "namespace": "argocd",
                "revision": 1,
                "values": "{\"apiVersionOverrides\":{},\"applicationSet\":{\"affinity\":{},\"allowAnyNamespace\":false,\"automountServiceAccountToken\":true,\"certificate\":{\"additionalHosts\":[],\"annotations\":{},\"domain\":\"\",\"duration\":\"\",\"enabled\":false,\"issuer\":{\"group\":\"\",\"kind\":\"\",\"name\":\"\"},\"privateKey\":{\"algorithm\":\"RSA\",\"encoding\":\"PKCS1\",\"rotationPolicy\":\"Never\",\"size\":2048},\"renewBefore\":\"\"},\"containerPorts\":{\"metrics\":8080,\"probe\":8081,\"webhook\":7000},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"deploymentAnnotations\":{},\"deploymentStrategy\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"emptyDir\":{\"sizeLimit\":\"\"},\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"ingress\":{\"annotations\":{},\"enabled\":false,\"extraHosts\":[],\"extraPaths\":[],\"extraRules\":[],\"extraTls\":[],\"hostname\":\"\",\"ingressClassName\":\"\",\"labels\":{},\"path\":\"/api/webhook\",\"pathType\":\"Prefix\",\"tls\":false},\"initContainers\":[],\"livenessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8080,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"scrapeTimeout\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"applicationset-controller\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"runtimeClassName\":\"\",\"service\":{\"annotations\":{},\"labels\":{},\"port\":7000,\"portName\":\"http-webhook\",\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"labels\":{},\"name\":\"argocd-applicationset-controller\"},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[]},\"commitServer\":{\"affinity\":{},\"automountServiceAccountToken\":false,\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"deploymentAnnotations\":{},\"deploymentStrategy\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"enabled\":false,\"extraArgs\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":30,\"periodSeconds\":30,\"timeoutSeconds\":5},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"labels\":{},\"portName\":\"metrics\",\"servicePort\":8087,\"type\":\"ClusterIP\"}},\"name\":\"commit-server\",\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"timeoutSeconds\":1},\"resources\":{},\"runtimeClassName\":\"\",\"service\":{\"annotations\":{},\"labels\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"labels\":{},\"name\":\"argocd-commit-server\"},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[]},\"configs\":{\"clusterCredentials\":{},\"cm\":{\"admin.enabled\":true,\"annotations\":{},\"application.instanceLabelKey\":\"argocd.argoproj.io/instance\",\"application.sync.impersonation.enabled\":false,\"create\":true,\"exec.enabled\":false,\"server.rbac.log.enforce.enable\":false,\"statusbadge.enabled\":false,\"timeout.hard.reconciliation\":\"0s\",\"timeout.reconciliation\":\"180s\"},\"cmp\":{\"annotations\":{},\"create\":false,\"plugins\":{}},\"credentialTemplates\":{},\"credentialTemplatesAnnotations\":{},\"gpg\":{\"annotations\":{},\"keys\":{}},\"params\":{\"annotations\":{},\"application.namespaces\":\"\",\"applicationsetcontroller.enable.progressive.syncs\":false,\"applicationsetcontroller.namespaces\":\"\",\"applicationsetcontroller.policy\":\"sync\",\"controller.ignore.normalizer.jq.timeout\":\"1s\",\"controller.operation.processors\":10,\"controller.repo.server.timeout.seconds\":60,\"controller.self.heal.timeout.seconds\":5,\"controller.status.processors\":20,\"controller.sync.timeout.seconds\":0,\"create\":true,\"otlp.address\":\"\",\"reposerver.parallelism.limit\":0,\"server.basehref\":\"/\",\"server.disable.auth\":false,\"server.enable.gzip\":true,\"server.enable.proxy.extension\":false,\"server.insecure\":false,\"server.rootpath\":\"\",\"server.staticassets\":\"/shared/app\",\"server.x.frame.options\":\"sameorigin\"},\"rbac\":{\"annotations\":{},\"create\":true,\"policy.csv\":\"\",\"policy.default\":\"\",\"policy.matchMode\":\"glob\",\"scopes\":\"[groups]\"},\"repositories\":{},\"repositoriesAnnotations\":{},\"secret\":{\"annotations\":{},\"argocdServerAdminPassword\":\"\",\"argocdServerAdminPasswordMtime\":\"\",\"azureDevops\":{\"password\":\"\",\"username\":\"\"},\"bitbucketServerSecret\":\"\",\"bitbucketUUID\":\"\",\"createSecret\":true,\"extra\":{},\"githubSecret\":\"\",\"gitlabSecret\":\"\",\"gogsSecret\":\"\",\"labels\":{}},\"ssh\":{\"annotations\":{},\"create\":true,\"extraHosts\":\"\",\"knownHosts\":\"[ssh.github.com]:443 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\\n[ssh.github.com]:443 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\\n[ssh.github.com]:443 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=\\nbitbucket.org ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBPIQmuzMBuKdWeF4+a2sjSSpBK0iqitSQ+5BM9KhpexuGt20JpTVM7u5BDZngncgrqDMbWdxMWWOGtZ9UgbqgZE=\\nbitbucket.org ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIIazEu89wgQZ4bqs3d63QSMzYVa0MuJ2e2gKTKqu+UUO\\nbitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDQeJzhupRu0u0cdegZIa8e86EG2qOCsIsD1Xw0xSeiPDlCr7kq97NLmMbpKTX6Esc30NuoqEEHCuc7yWtwp8dI76EEEB1VqY9QJq6vk+aySyboD5QF61I/1WeTwu+deCbgKMGbUijeXhtfbxSxm6JwGrXrhBdofTsbKRUsrN1WoNgUa8uqN1Vx6WAJw1JHPhglEGGHea6QICwJOAr/6mrui/oB7pkaWKHj3z7d1IC4KWLtY47elvjbaTlkN04Kc/5LFEirorGYVbt15kAUlqGM65pk6ZBxtaO3+30LVlORZkxOh+LKL/BvbZ/iRNhItLqNyieoQj/uh/7Iv4uyH/cV/0b4WDSd3DptigWq84lJubb9t/DnZlrJazxyDCulTmKdOR7vs9gMTo+uoIrPSb8ScTtvw65+odKAlBj59dhnVp9zd7QUojOpXlL62Aw56U4oO+FALuevvMjiWeavKhJqlR7i5n9srYcrNV7ttmDw7kf/97P5zauIhxcjX+xHv4M=\\ngithub.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\\ngithub.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\\ngithub.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=\\ngitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=\\ngitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf\\ngitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9\\nssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\\nvs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\\n\"},\"styles\":\"\",\"tls\":{\"annotations\":{},\"certificates\":{},\"create\":true}},\"controller\":{\"affinity\":{},\"automountServiceAccountToken\":true,\"clusterRoleRules\":{\"enabled\":false,\"rules\":[]},\"containerPorts\":{\"metrics\":8082},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"deploymentAnnotations\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"dynamicClusterDistribution\":false,\"emptyDir\":{\"sizeLimit\":\"\"},\"env\":[],\"envFrom\":[],\"extraArgs\":[],\"extraContainers\":[],\"heartbeatTime\":10,\"hostNetwork\":false,\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"initContainers\":[],\"metrics\":{\"applicationLabels\":{\"enabled\":false,\"labels\":[]},\"enabled\":false,\"rules\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"namespace\":\"\",\"selector\":{},\"spec\":[]},\"scrapeTimeout\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8082,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"application-controller\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"revisionHistoryLimit\":5,\"runtimeClassName\":\"\",\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"labels\":{},\"name\":\"argocd-application-controller\"},\"statefulsetAnnotations\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]},\"crds\":{\"additionalLabels\":{},\"annotations\":{},\"install\":true,\"keep\":true},\"createAggregateRoles\":false,\"createClusterRoles\":true,\"dex\":{\"affinity\":{},\"automountServiceAccountToken\":true,\"certificateSecret\":{\"annotations\":{},\"ca\":\"\",\"crt\":\"\",\"enabled\":false,\"key\":\"\",\"labels\":{}},\"containerPorts\":{\"grpc\":5557,\"http\":5556,\"metrics\":5558},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"deploymentAnnotations\":{},\"deploymentStrategy\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"emptyDir\":{\"sizeLimit\":\"\"},\"enabled\":true,\"env\":[],\"envFrom\":[],\"extraArgs\":[],\"extraContainers\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"ghcr.io/dexidp/dex\",\"tag\":\"v2.42.0\"},\"imagePullSecrets\":[],\"initContainers\":[],\"initImage\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"resources\":{},\"tag\":\"\"},\"livenessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"httpPath\":\"/healthz/live\",\"httpPort\":\"metrics\",\"httpScheme\":\"HTTP\",\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"labels\":{},\"portName\":\"http-metrics\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"dex-server\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"httpPath\":\"/healthz/ready\",\"httpPort\":\"metrics\",\"httpScheme\":\"HTTP\",\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{},\"runtimeClassName\":\"\",\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"argocd-dex-server\"},\"servicePortGrpc\":5557,\"servicePortGrpcName\":\"grpc\",\"servicePortHttp\":5556,\"servicePortHttpName\":\"http\",\"servicePortMetrics\":5558,\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]},\"externalRedis\":{\"existingSecret\":\"\",\"host\":\"\",\"password\":\"\",\"port\":6379,\"secretAnnotations\":{},\"username\":\"\"},\"extraObjects\":[],\"fullnameOverride\":\"\",\"global\":{\"addPrometheusAnnotations\":false,\"additionalLabels\":{},\"affinity\":{\"nodeAffinity\":{\"matchExpressions\":[],\"type\":\"hard\"},\"podAntiAffinity\":\"soft\"},\"certificateAnnotations\":{},\"deploymentAnnotations\":{},\"deploymentStrategy\":{},\"domain\":\"argocd.example.com\",\"dualStack\":{\"ipFamilies\":[],\"ipFamilyPolicy\":\"\"},\"env\":[],\"hostAliases\":[],\"image\":{\"imagePullPolicy\":\"IfNotPresent\",\"repository\":\"quay.io/argoproj/argocd\",\"tag\":\"\"},\"imagePullSecrets\":[],\"logging\":{\"format\":\"text\",\"level\":\"info\"},\"networkPolicy\":{\"create\":false,\"defaultDenyIngress\":false},\"nodeSelector\":{\"kubernetes.io/os\":\"linux\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"revisionHistoryLimit\":3,\"runtimeClassName\":\"\",\"securityContext\":{},\"statefulsetAnnotations\":{},\"tolerations\":[],\"topologySpreadConstraints\":[]},\"kubeVersionOverride\":\"\",\"nameOverride\":\"argocd\",\"namespaceOverride\":\"\",\"notifications\":{\"affinity\":{},\"argocdUrl\":\"\",\"automountServiceAccountToken\":true,\"clusterRoleRules\":{\"rules\":[]},\"cm\":{\"create\":true},\"containerPorts\":{\"metrics\":9001},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"context\":{},\"deploymentAnnotations\":{},\"deploymentStrategy\":{\"type\":\"Recreate\"},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"enabled\":true,\"extraArgs\":[],\"extraContainers\":[],\"extraEnv\":[],\"extraEnvFrom\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"initContainers\":[],\"livenessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"logFormat\":\"\",\"logLevel\":\"\",\"metrics\":{\"enabled\":false,\"port\":9001,\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"labels\":{},\"portName\":\"http-metrics\",\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"metricRelabelings\":[],\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"notifications-controller\",\"nodeSelector\":{},\"notifiers\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":false,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"resources\":{},\"runtimeClassName\":\"\",\"secret\":{\"annotations\":{},\"create\":true,\"items\":{},\"labels\":{},\"name\":\"argocd-notifications-secret\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"labels\":{},\"name\":\"argocd-notifications-controller\"},\"subscriptions\":[],\"templates\":{},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[],\"triggers\":{}},\"openshift\":{\"enabled\":false},\"redis\":{\"affinity\":{},\"automountServiceAccountToken\":true,\"containerPorts\":{\"metrics\":9121,\"redis\":6379},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true},\"deploymentAnnotations\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"enabled\":true,\"env\":[],\"envFrom\":[],\"exporter\":{\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"enabled\":false,\"env\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"public.ecr.aws/bitnami/redis-exporter\",\"tag\":\"1.67.0\"},\"livenessProbe\":{\"enabled\":false,\"failureThreshold\":5,\"initialDelaySeconds\":30,\"periodSeconds\":15,\"successThreshold\":1,\"timeoutSeconds\":15},\"readinessProbe\":{\"enabled\":false,\"failureThreshold\":5,\"initialDelaySeconds\":30,\"periodSeconds\":15,\"successThreshold\":1,\"timeoutSeconds\":15},\"resources\":{}},\"extraArgs\":[],\"extraContainers\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"public.ecr.aws/docker/library/redis\",\"tag\":\"7.4.2-alpine\"},\"imagePullSecrets\":[],\"initContainers\":[],\"livenessProbe\":{\"enabled\":false,\"failureThreshold\":5,\"initialDelaySeconds\":30,\"periodSeconds\":15,\"successThreshold\":1,\"timeoutSeconds\":15},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"clusterIP\":\"None\",\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":9121,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"redis\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"enabled\":false,\"failureThreshold\":5,\"initialDelaySeconds\":30,\"periodSeconds\":15,\"successThreshold\":1,\"timeoutSeconds\":15},\"resources\":{},\"runtimeClassName\":\"\",\"securityContext\":{\"runAsNonRoot\":true,\"runAsUser\":999,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"service\":{\"annotations\":{},\"labels\":{}},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":false,\"create\":false,\"name\":\"\"},\"servicePort\":6379,\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]},\"redis-ha\":{\"additionalAffinities\":{},\"affinity\":\"\",\"auth\":true,\"containerSecurityContext\":{\"readOnlyRootFilesystem\":true},\"enabled\":false,\"existingSecret\":\"argocd-redis\",\"exporter\":{\"enabled\":false,\"image\":\"public.ecr.aws/bitnami/redis-exporter\",\"tag\":\"1.58.0\"},\"haproxy\":{\"additionalAffinities\":{},\"affinity\":\"\",\"containerSecurityContext\":{\"readOnlyRootFilesystem\":true},\"enabled\":true,\"hardAntiAffinity\":true,\"labels\":{\"app.kubernetes.io/name\":\"argocd-redis-ha-haproxy\"},\"metrics\":{\"enabled\":true},\"tolerations\":[]},\"hardAntiAffinity\":true,\"image\":{\"repository\":\"public.ecr.aws/docker/library/redis\",\"tag\":\"7.4.2-alpine\"},\"persistentVolume\":{\"enabled\":false},\"redis\":{\"config\":{\"save\":\"\\\"\\\"\"},\"masterGroupName\":\"argocd\"},\"tolerations\":[],\"topologySpreadConstraints\":{\"enabled\":false,\"maxSkew\":\"\",\"topologyKey\":\"\",\"whenUnsatisfiable\":\"\"}},\"redisSecretInit\":{\"affinity\":{},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"enabled\":true,\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"jobAnnotations\":{},\"name\":\"redis-secret-init\",\"nodeSelector\":{},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"resources\":{},\"securityContext\":{},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"tolerations\":[]},\"repoServer\":{\"affinity\":{},\"automountServiceAccountToken\":true,\"autoscaling\":{\"behavior\":{},\"enabled\":false,\"maxReplicas\":5,\"metrics\":[],\"minReplicas\":1,\"targetCPUUtilizationPercentage\":50,\"targetMemoryUtilizationPercentage\":50},\"certificateSecret\":{\"annotations\":{},\"ca\":\"\",\"crt\":\"\",\"enabled\":false,\"key\":\"\",\"labels\":{}},\"clusterRoleRules\":{\"enabled\":false,\"rules\":[]},\"containerPorts\":{\"metrics\":8084,\"server\":8081},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"deploymentAnnotations\":{},\"deploymentStrategy\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"emptyDir\":{\"sizeLimit\":\"\"},\"env\":[],\"envFrom\":[],\"existingVolumes\":{},\"extraArgs\":[],\"extraContainers\":[],\"hostNetwork\":false,\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"initContainers\":[],\"lifecycle\":{},\"livenessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8084,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"scrapeTimeout\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"repo-server\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"rbac\":[],\"readinessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"runtimeClassName\":\"\",\"service\":{\"annotations\":{},\"labels\":{},\"port\":8081,\"portName\":\"tcp-repo-server\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"labels\":{},\"name\":\"\"},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[],\"useEphemeralHelmWorkingDir\":true,\"volumeMounts\":[],\"volumes\":[]},\"server\":{\"affinity\":{},\"automountServiceAccountToken\":true,\"autoscaling\":{\"behavior\":{},\"enabled\":false,\"maxReplicas\":5,\"metrics\":[],\"minReplicas\":1,\"targetCPUUtilizationPercentage\":50,\"targetMemoryUtilizationPercentage\":50},\"certificate\":{\"additionalHosts\":[],\"annotations\":{},\"domain\":\"\",\"duration\":\"\",\"enabled\":false,\"issuer\":{\"group\":\"\",\"kind\":\"\",\"name\":\"\"},\"privateKey\":{\"algorithm\":\"RSA\",\"encoding\":\"PKCS1\",\"rotationPolicy\":\"Never\",\"size\":2048},\"renewBefore\":\"\",\"secretTemplateAnnotations\":{},\"usages\":[]},\"certificateSecret\":{\"annotations\":{},\"crt\":\"\",\"enabled\":false,\"key\":\"\",\"labels\":{}},\"clusterRoleRules\":{\"enabled\":false,\"rules\":[]},\"containerPorts\":{\"metrics\":8083,\"server\":8080},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"deploymentAnnotations\":{},\"deploymentStrategy\":{},\"dnsConfig\":{},\"dnsPolicy\":\"ClusterFirst\",\"emptyDir\":{\"sizeLimit\":\"\"},\"env\":[],\"envFrom\":[],\"extensions\":{\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"capabilities\":{\"drop\":[\"ALL\"]},\"readOnlyRootFilesystem\":true,\"runAsNonRoot\":true,\"runAsUser\":1000,\"seccompProfile\":{\"type\":\"RuntimeDefault\"}},\"enabled\":false,\"extensionList\":[],\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"quay.io/argoprojlabs/argocd-extension-installer\",\"tag\":\"v0.0.8\"},\"resources\":{}},\"extraArgs\":[],\"extraContainers\":[],\"hostNetwork\":false,\"image\":{\"imagePullPolicy\":\"\",\"repository\":\"\",\"tag\":\"\"},\"imagePullSecrets\":[],\"ingress\":{\"annotations\":{\"nginx.ingress.kubernetes.io/force-ssl-redirect\":\"true\",\"nginx.ingress.kubernetes.io/ssl-passthrough\":\"true\"},\"aws\":{\"backendProtocolVersion\":\"GRPC\",\"serviceType\":\"NodePort\"},\"controller\":\"generic\",\"enabled\":true,\"extraHosts\":[],\"extraPaths\":[],\"extraRules\":[],\"extraTls\":[],\"gke\":{\"backendConfig\":{},\"frontendConfig\":{},\"managedCertificate\":{\"create\":true,\"extraDomains\":[]}},\"hostname\":\"argocd.example.com\",\"ingressClassName\":\"nginx-internal\",\"labels\":{},\"path\":\"/\",\"pathType\":\"Prefix\",\"tls\":false},\"ingressGrpc\":{\"annotations\":{},\"enabled\":false,\"extraHosts\":[],\"extraPaths\":[],\"extraRules\":[],\"extraTls\":[],\"hostname\":\"\",\"ingressClassName\":\"\",\"labels\":{},\"path\":\"/\",\"pathType\":\"Prefix\",\"tls\":false},\"initContainers\":[],\"lifecycle\":{},\"livenessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"metrics\":{\"enabled\":false,\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"labels\":{},\"portName\":\"http-metrics\",\"servicePort\":8083,\"type\":\"ClusterIP\"},\"serviceMonitor\":{\"additionalLabels\":{},\"annotations\":{},\"enabled\":false,\"honorLabels\":false,\"interval\":\"30s\",\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scheme\":\"\",\"scrapeTimeout\":\"\",\"selector\":{},\"tlsConfig\":{}}},\"name\":\"server\",\"nodeSelector\":{},\"pdb\":{\"annotations\":{},\"enabled\":false,\"labels\":{},\"maxUnavailable\":\"\",\"minAvailable\":\"\"},\"podAnnotations\":{},\"podLabels\":{},\"priorityClassName\":\"\",\"readinessProbe\":{\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"replicas\":1,\"resources\":{},\"route\":{\"annotations\":{},\"enabled\":false,\"hostname\":\"\",\"termination_policy\":\"None\",\"termination_type\":\"passthrough\"},\"runtimeClassName\":\"\",\"service\":{\"annotations\":{},\"externalIPs\":[],\"externalTrafficPolicy\":\"Cluster\",\"labels\":{},\"loadBalancerClass\":\"\",\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePortHttp\":30080,\"nodePortHttps\":30443,\"servicePortHttp\":80,\"servicePortHttpName\":\"http\",\"servicePortHttps\":443,\"servicePortHttpsAppProtocol\":\"\",\"servicePortHttpsName\":\"https\",\"sessionAffinity\":\"None\",\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"labels\":{},\"name\":\"argocd-server\"},\"terminationGracePeriodSeconds\":30,\"tolerations\":[],\"topologySpreadConstraints\":[],\"volumeMounts\":[],\"volumes\":[]}}",
                "version": "7.7.5"
              }
            ],
            "name": "argocd",
            "namespace": "argocd",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": "https://argoproj.github.io/argo-helm",
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_list": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## Argo CD configuration\n## Ref: https://github.com/argoproj/argo-cd\n##\n\n# -- Provide a name in place of `argocd`\nnameOverride: argocd\n# -- String to fully override `\"argo-cd.fullname\"`\nfullnameOverride: \"\"\n# -- Override the namespace\n# @default -- `.Release.Namespace`\nnamespaceOverride: \"\"\n# -- Override the Kubernetes version, which is used to evaluate certain manifests\nkubeVersionOverride: \"\"\n# Override APIVersions\n# If you want to template helm charts but cannot access k8s API server\n# you can set api versions here\napiVersionOverrides: {}\n\n# -- Create aggregated roles that extend existing cluster roles to interact with argo-cd resources\n## Ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles\ncreateAggregateRoles: false\n# -- Create cluster roles for cluster-wide installation.\n## Used when you manage applications in the same cluster where Argo CD runs\ncreateClusterRoles: true\n\nopenshift:\n  # -- enables using arbitrary uid for argo repo server\n  enabled: false\n\n## Custom resource configuration\ncrds:\n  # -- Install and upgrade CRDs\n  install: true\n  # -- Keep CRDs on chart uninstall\n  keep: true\n  # -- Annotations to be added to all CRDs\n  annotations: {}\n  # -- Addtional labels to be added to all CRDs\n  additionalLabels: {}\n\n## Globally shared configuration\nglobal:\n  # -- Default domain used by all components\n  ## Used for ingresses, certificates, SSO, notifications, etc.\n  domain: argocd.example.com\n\n  # -- Runtime class name for all components\n  runtimeClassName: \"\"\n\n  # -- Common labels for the all resources\n  additionalLabels: {}\n    # app: argo-cd\n\n  # -- Number of old deployment ReplicaSets to retain. The rest will be garbage collected.\n  revisionHistoryLimit: 3\n\n  # Default image used by all components\n  image:\n    # -- If defined, a repository applied to all Argo CD deployments\n    repository: quay.io/argoproj/argocd\n    # -- Overrides the global Argo CD image tag whose default is the chart appVersion\n    tag: \"\"\n    # -- If defined, a imagePullPolicy applied to all Argo CD deployments\n    imagePullPolicy: IfNotPresent\n\n  # -- Secrets with credentials to pull images from a private registry\n  imagePullSecrets: []\n\n  # Default logging options used by all components\n  logging:\n    # -- Set the global logging format. Either: `text` or `json`\n    format: text\n    # -- Set the global logging level. One of: `debug`, `info`, `warn` or `error`\n    level: info\n\n  # -- Annotations for the all deployed Statefulsets\n  statefulsetAnnotations: {}\n\n  # -- Annotations for the all deployed Deployments\n  deploymentAnnotations: {}\n\n  # -- Annotations for the all deployed pods\n  podAnnotations: {}\n\n  # -- Labels for the all deployed pods\n  podLabels: {}\n\n  # -- Add Prometheus scrape annotations to all metrics services. This can be used as an alternative to the ServiceMonitors.\n  addPrometheusAnnotations: false\n\n  # -- Toggle and define pod-level security context.\n  # @default -- `{}` (See [values.yaml])\n  securityContext: {}\n  #  runAsUser: 999\n  #  runAsGroup: 999\n  #  fsGroup: 999\n\n  # -- Mapping between IP and hostnames that will be injected as entries in the pod's hosts files\n  hostAliases: []\n  # - ip: 10.20.30.40\n  #   hostnames:\n  #   - git.myhostname\n\n  # Configure dual-stack used by all component services\n  dualStack:\n    # -- IP family policy to configure dual-stack see [Configure dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/#services)\n    ipFamilyPolicy: \"\"\n    # -- IP families that should be supported and the order in which they should be applied to ClusterIP as well. Can be IPv4 and/or IPv6.\n    ipFamilies: []\n\n  # Default network policy rules used by all components\n  networkPolicy:\n    # -- Create NetworkPolicy objects for all components\n    create: false\n    # -- Default deny all ingress traffic\n    defaultDenyIngress: false\n\n  # -- Default priority class for all components\n  priorityClassName: \"\"\n\n  # -- Default node selector for all components\n  nodeSelector:\n    kubernetes.io/os: linux\n\n  # -- Default tolerations for all components\n  tolerations: []\n\n  # Default affinity preset for all components\n  affinity:\n    # -- Default pod anti-affinity rules. Either: `none`, `soft` or `hard`\n    podAntiAffinity: soft\n    # Node affinity rules\n    nodeAffinity:\n      # -- Default node affinity rules. Either: `none`, `soft` or `hard`\n      type: hard\n      # -- Default match expressions for node affinity\n      matchExpressions: []\n        # - key: topology.kubernetes.io/zone\n        #   operator: In\n        #   values:\n        #    - antarctica-east1\n        #    - antarctica-west1\n\n  # -- Default [TopologySpreadConstraints] rules for all components\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector of the component\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy for the all deployed Deployments\n  deploymentStrategy: {}\n    # type: RollingUpdate\n    # rollingUpdate:\n    #   maxSurge: 25%\n    #   maxUnavailable: 25%\n\n  # -- Environment variables to pass to all deployed Deployments\n  env: []\n\n  # -- Annotations for the all deployed Certificates\n  certificateAnnotations: {}\n\n## Argo Configs\nconfigs:\n  # General Argo CD configuration. Any values you put under `.configs.cm` are passed to argocd-cm ConfigMap.\n  ## Ref: https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/argocd-cm.yaml\n  cm:\n    # -- Create the argocd-cm configmap for [declarative setup]\n    create: true\n\n    # -- Annotations to be added to argocd-cm configmap\n    annotations: {}\n\n    # -- The name of tracking label used by Argo CD for resource pruning\n    application.instanceLabelKey: argocd.argoproj.io/instance\n\n    # -- Enable control of the service account used for the sync operation (alpha)\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/app-sync-using-impersonation/\n    application.sync.impersonation.enabled: false\n\n    # -- Enable logs RBAC enforcement\n    ## Ref: https://argo-cd.readthedocs.io/en/latest/operator-manual/upgrading/2.3-2.4/#enable-logs-rbac-enforcement\n    server.rbac.log.enforce.enable: false\n\n    # -- Enable exec feature in Argo UI\n    ## Ref: https://argo-cd.readthedocs.io/en/latest/operator-manual/rbac/#exec-resource\n    exec.enabled: false\n\n    # -- Enable local admin user\n    ## Ref: https://argo-cd.readthedocs.io/en/latest/faq/#how-to-disable-admin-user\n    admin.enabled: true\n\n    # -- Timeout to discover if a new manifests version got published to the repository\n    timeout.reconciliation: 180s\n\n    # -- Timeout to refresh application data as well as target manifests cache\n    timeout.hard.reconciliation: 0s\n\n    # -- Enable Status Badge\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/user-guide/status-badge/\n    statusbadge.enabled: false\n\n    # Dex configuration\n    # dex.config: |\n    #   connectors:\n    #     # GitHub example\n    #     - type: github\n    #       id: github\n    #       name: GitHub\n    #       config:\n    #         clientID: aabbccddeeff00112233\n    #         clientSecret: $dex.github.clientSecret # Alternatively $\u003csome_K8S_secret\u003e:dex.github.clientSecret\n    #         orgs:\n    #         - name: your-github-org\n\n    # OIDC configuration as an alternative to dex (optional).\n    # oidc.config: |\n    #   name: AzureAD\n    #   issuer: https://login.microsoftonline.com/TENANT_ID/v2.0\n    #   clientID: CLIENT_ID\n    #   clientSecret: $oidc.azuread.clientSecret\n    #   rootCA: |\n    #     -----BEGIN CERTIFICATE-----\n    #     ... encoded certificate data here ...\n    #     -----END CERTIFICATE-----\n    #   requestedIDTokenClaims:\n    #     groups:\n    #       essential: true\n    #   requestedScopes:\n    #     - openid\n    #     - profile\n    #     - email\n\n    # Extension Configuration\n    ## Ref: https://argo-cd.readthedocs.io/en/latest/developer-guide/extensions/proxy-extensions/\n    # extension.config: |\n    #   extensions:\n    #   - name: httpbin\n    #     backend:\n    #       connectionTimeout: 2s\n    #       keepAlive: 15s\n    #       idleConnectionTimeout: 60s\n    #       maxIdleConnections: 30\n    #       services:\n    #       - url: http://httpbin.org\n    #         headers:\n    #         - name: some-header\n    #           value: '$some.argocd.secret.key'\n    #         cluster:\n    #           name: some-cluster\n    #           server: https://some-cluster\n\n  # Argo CD configuration parameters\n  ## Ref: https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/argocd-cmd-params-cm.yaml\n  params:\n    # -- Create the argocd-cmd-params-cm configmap\n    # If false, it is expected the configmap will be created by something else.\n    create: true\n\n    # -- Annotations to be added to the argocd-cmd-params-cm ConfigMap\n    annotations: {}\n\n    ## Generic parameters\n    # -- Open-Telemetry collector address: (e.g. \"otel-collector:4317\")\n    otlp.address: ''\n\n    ## Controller Properties\n    # -- Number of application status processors\n    controller.status.processors: 20\n    # -- Number of application operation processors\n    controller.operation.processors: 10\n    # -- Specifies timeout between application self heal attempts\n    controller.self.heal.timeout.seconds: 5\n    # -- Repo server RPC call timeout seconds.\n    controller.repo.server.timeout.seconds: 60\n    # -- Specifies the timeout after which a sync would be terminated. 0 means no timeout\n    controller.sync.timeout.seconds: 0\n\n    ## Server properties\n    # -- Run server without TLS\n    ## NOTE: This value should be set when you generate params by other means as it changes ports used by ingress template.\n    server.insecure: false\n    # -- Value for base href in index.html. Used if Argo CD is running behind reverse proxy under subpath different from /\n    server.basehref: /\n    # -- Used if Argo CD is running behind reverse proxy under subpath different from /\n    server.rootpath: ''\n    # -- Directory path that contains additional static assets\n    server.staticassets: /shared/app\n    # -- Disable Argo CD RBAC for user authentication\n    server.disable.auth: false\n    # -- Enable GZIP compression\n    server.enable.gzip: true\n    # -- Enable proxy extension feature. (proxy extension is in Alpha phase)\n    server.enable.proxy.extension: false\n    # -- Set X-Frame-Options header in HTTP responses to value. To disable, set to \"\".\n    server.x.frame.options: sameorigin\n\n    ## Repo-server properties\n    # -- Limit on number of concurrent manifests generate requests. Any value less the 1 means no limit.\n    reposerver.parallelism.limit: 0\n\n    ## ApplicationSet Properties\n    # -- Modify how application is synced between the generator and the cluster. One of: `sync`, `create-only`, `create-update`, `create-delete`\n    applicationsetcontroller.policy: sync\n    # -- Enables use of the Progressive Syncs capability\n    applicationsetcontroller.enable.progressive.syncs: false\n    # -- A list of glob patterns specifying where to look for ApplicationSet resources. (e.g. `\"argocd,argocd-appsets-*\"`)\n    # @default -- `\"\"` (default is only the ns where the controller is installed)\n    ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/applicationset/Appset-Any-Namespace/\n    applicationsetcontroller.namespaces: \"\"\n\n    # -- Enables [Applications in any namespace]\n    ## List of additional namespaces where applications may be created in and reconciled from.\n    ## The namespace where Argo CD is installed to will always be allowed.\n    ## Set comma-separated list. (e.g. app-team-one, app-team-two)\n    application.namespaces: \"\"\n\n    # -- JQ Path expression timeout\n    ## By default, the evaluation of a JQPathExpression is limited to one second.\n    ## If you encounter a \"JQ patch execution timed out\" error message due to a complex JQPathExpression\n    ## that requires more time to evaluate, you can extend the timeout period.\n    controller.ignore.normalizer.jq.timeout: \"1s\"\n\n  # Argo CD RBAC policy configuration\n  ## Ref: https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/rbac.md\n  rbac:\n    # -- Create the argocd-rbac-cm configmap with ([Argo CD RBAC policy]) definitions.\n    # If false, it is expected the configmap will be created by something else.\n    # Argo CD will not work if there is no configmap created with the name above.\n    create: true\n\n    # -- Annotations to be added to argocd-rbac-cm configmap\n    annotations: {}\n\n    # -- The name of the default role which Argo CD will falls back to, when authorizing API requests (optional).\n    # If omitted or empty, users may be still be able to login, but will see no apps, projects, etc...\n    policy.default: ''\n\n    # -- File containing user-defined policies and role definitions.\n    # @default -- `''` (See [values.yaml])\n    policy.csv: ''\n    # Policy rules are in the form:\n    #  p, subject, resource, action, object, effect\n    # Role definitions and bindings are in the form:\n    #  g, subject, inherited-subject\n    # policy.csv: |\n    #   p, role:org-admin, applications, *, */*, allow\n    #   p, role:org-admin, clusters, get, *, allow\n    #   p, role:org-admin, repositories, *, *, allow\n    #   p, role:org-admin, logs, get, *, allow\n    #   p, role:org-admin, exec, create, */*, allow\n    #   g, your-github-org:your-team, role:org-admin\n\n    # -- OIDC scopes to examine during rbac enforcement (in addition to `sub` scope).\n    # The scope value can be a string, or a list of strings.\n    scopes: \"[groups]\"\n\n    # -- Matcher function for Casbin, `glob` for glob matcher and `regex` for regex matcher.\n    policy.matchMode: \"glob\"\n\n  # GnuPG public keys for commit verification\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/user-guide/gpg-verification/\n  gpg:\n    # -- Annotations to be added to argocd-gpg-keys-cm configmap\n    annotations: {}\n\n    # -- [GnuPG] public keys to add to the keyring\n    # @default -- `{}` (See [values.yaml])\n    ## Note: Public keys should be exported with `gpg --export --armor \u003cKEY\u003e`\n    keys: {}\n      # 4AEE18F83AFDEB23: |\n      #   -----BEGIN PGP PUBLIC KEY BLOCK-----\n      #   ...\n      #   -----END PGP PUBLIC KEY BLOCK-----\n\n  # SSH known hosts for Git repositories\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/#ssh-known-host-public-keys\n  ssh:\n    # -- Specifies if the argocd-ssh-known-hosts-cm configmap should be created by Helm.\n    create: true\n\n    # -- Annotations to be added to argocd-ssh-known-hosts-cm configmap\n    annotations: {}\n\n    # -- Known hosts to be added to the known host list by default.\n    # @default -- See [values.yaml]\n    knownHosts: |\n      [ssh.github.com]:443 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\n      [ssh.github.com]:443 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\n      [ssh.github.com]:443 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=\n      bitbucket.org ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBPIQmuzMBuKdWeF4+a2sjSSpBK0iqitSQ+5BM9KhpexuGt20JpTVM7u5BDZngncgrqDMbWdxMWWOGtZ9UgbqgZE=\n      bitbucket.org ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIIazEu89wgQZ4bqs3d63QSMzYVa0MuJ2e2gKTKqu+UUO\n      bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDQeJzhupRu0u0cdegZIa8e86EG2qOCsIsD1Xw0xSeiPDlCr7kq97NLmMbpKTX6Esc30NuoqEEHCuc7yWtwp8dI76EEEB1VqY9QJq6vk+aySyboD5QF61I/1WeTwu+deCbgKMGbUijeXhtfbxSxm6JwGrXrhBdofTsbKRUsrN1WoNgUa8uqN1Vx6WAJw1JHPhglEGGHea6QICwJOAr/6mrui/oB7pkaWKHj3z7d1IC4KWLtY47elvjbaTlkN04Kc/5LFEirorGYVbt15kAUlqGM65pk6ZBxtaO3+30LVlORZkxOh+LKL/BvbZ/iRNhItLqNyieoQj/uh/7Iv4uyH/cV/0b4WDSd3DptigWq84lJubb9t/DnZlrJazxyDCulTmKdOR7vs9gMTo+uoIrPSb8ScTtvw65+odKAlBj59dhnVp9zd7QUojOpXlL62Aw56U4oO+FALuevvMjiWeavKhJqlR7i5n9srYcrNV7ttmDw7kf/97P5zauIhxcjX+xHv4M=\n      github.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=\n      github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl\n      github.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCj7ndNxQowgcQnjshcLrqPEiiphnt+VTTvDP6mHBL9j1aNUkY4Ue1gvwnGLVlOhGeYrnZaMgRK6+PKCUXaDbC7qtbW8gIkhL7aGCsOr/C56SJMy/BCZfxd1nWzAOxSDPgVsmerOBYfNqltV9/hWCqBywINIR+5dIg6JTJ72pcEpEjcYgXkE2YEFXV1JHnsKgbLWNlhScqb2UmyRkQyytRLtL+38TGxkxCflmO+5Z8CSSNY7GidjMIZ7Q4zMjA2n1nGrlTDkzwDCsw+wqFPGQA179cnfGWOWRVruj16z6XyvxvjJwbz0wQZ75XK5tKSb7FNyeIEs4TT4jk+S4dhPeAUC5y+bDYirYgM4GC7uEnztnZyaVWQ7B381AK4Qdrwt51ZqExKbQpTUNn+EjqoTwvqNj4kqx5QUCI0ThS/YkOxJCXmPUWZbhjpCg56i+2aB6CmK2JGhn57K5mj0MNdBXA4/WnwH6XoPWJzK5Nyu2zB3nAZp+S5hpQs+p1vN1/wsjk=\n      gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=\n      gitlab.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAfuCHKVTjquxvt6CM6tdG4SLp1Btn/nOeHHE5UOzRdf\n      gitlab.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCsj2bNKTBSpIYDEGk9KxsGh3mySTRgMtXL583qmBpzeQ+jqCMRgBqB98u3z++J1sKlXHWfM9dyhSevkMwSbhoR8XIq/U0tCNyokEi/ueaBMCvbcTHhO7FcwzY92WK4Yt0aGROY5qX2UKSeOvuP4D6TPqKF1onrSzH9bx9XUf2lEdWT/ia1NEKjunUqu1xOB/StKDHMoX4/OKyIzuS0q/T1zOATthvasJFoPrAjkohTyaDUz2LN5JoH839hViyEG82yB+MjcFV5MU3N1l1QL3cVUCh93xSaua1N85qivl+siMkPGbO5xR/En4iEY6K2XPASUEMaieWVNTRCtJ4S8H+9\n      ssh.dev.azure.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\n      vs-ssh.visualstudio.com ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC7Hr1oTWqNqOlzGJOfGJ4NakVyIzf1rXYd4d7wo6jBlkLvCA4odBlL0mDUyZ0/QUfTTqeu+tm22gOsv+VrVTMk6vwRU75gY/y9ut5Mb3bR5BV58dKXyq9A9UeB5Cakehn5Zgm6x1mKoVyf+FFn26iYqXJRgzIZZcZ5V6hrE0Qg39kZm4az48o0AUbf6Sp4SLdvnuMa2sVNwHBboS7EJkm57XQPVU3/QpyNLHbWDdzwtrlS+ez30S3AdYhLKEOxAG8weOnyrtLJAUen9mTkol8oII1edf7mWWbWVf0nBmly21+nZcmCTISQBtdcyPaEno7fFQMDD26/s0lfKob4Kw8H\n\n    # -- Additional known hosts for private repositories\n    extraHosts: ''\n\n  # Repository TLS certificates\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/#repositories-using-self-signed-tls-certificates-or-are-signed-by-custom-ca\n  tls:\n    # -- Annotations to be added to argocd-tls-certs-cm configmap\n    annotations: {}\n\n    # -- TLS certificates for Git repositories\n    # @default -- `{}` (See [values.yaml])\n    certificates: {}\n      # server.example.com: |\n      #   -----BEGIN CERTIFICATE-----\n      #   ...\n      #   -----END CERTIFICATE-----\n\n    # -- Specifies if the argocd-tls-certs-cm configmap should be created by Helm.\n    create: true\n\n  # ConfigMap for Config Management Plugins\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/config-management-plugins/\n  cmp:\n    # -- Create the argocd-cmp-cm configmap\n    create: false\n\n    # -- Annotations to be added to argocd-cmp-cm configmap\n    annotations: {}\n\n    # -- Plugin yaml files to be added to argocd-cmp-cm\n    plugins: {}\n      # --- First plugin\n      # my-plugin:\n      #   init:\n      #     command: [sh]\n      #     args: [-c, 'echo \"Initializing...\"']\n      #   generate:\n      #     command: [sh, -c]\n      #     args:\n      #       - |\n      #         echo \"{\\\"kind\\\": \\\"ConfigMap\\\", \\\"apiVersion\\\": \\\"v1\\\", \\\"metadata\\\": { \\\"name\\\": \\\"$ARGOCD_APP_NAME\\\", \\\"namespace\\\": \\\"$ARGOCD_APP_NAMESPACE\\\", \\\"annotations\\\": {\\\"Foo\\\": \\\"$ARGOCD_ENV_FOO\\\", \\\"KubeVersion\\\": \\\"$KUBE_VERSION\\\", \\\"KubeApiVersion\\\": \\\"$KUBE_API_VERSIONS\\\",\\\"Bar\\\": \\\"baz\\\"}}}\"\n      #   discover:\n      #     fileName: \"./subdir/s*.yaml\"\n      #     find:\n      #       glob: \"**/Chart.yaml\"\n      #       command: [sh, -c, find . -name env.yaml]\n\n      # --- Second plugin\n      # my-plugin2:\n      #   init:\n      #     command: [sh]\n      #     args: [-c, 'echo \"Initializing...\"']\n      #   generate:\n      #     command: [sh, -c]\n      #     args:\n      #       - |\n      #         echo \"{\\\"kind\\\": \\\"ConfigMap\\\", \\\"apiVersion\\\": \\\"v1\\\", \\\"metadata\\\": { \\\"name\\\": \\\"$ARGOCD_APP_NAME\\\", \\\"namespace\\\": \\\"$ARGOCD_APP_NAMESPACE\\\", \\\"annotations\\\": {\\\"Foo\\\": \\\"$ARGOCD_ENV_FOO\\\", \\\"KubeVersion\\\": \\\"$KUBE_VERSION\\\", \\\"KubeApiVersion\\\": \\\"$KUBE_API_VERSIONS\\\",\\\"Bar\\\": \\\"baz\\\"}}}\"\n      #   discover:\n      #     fileName: \"./subdir/s*.yaml\"\n      #     find:\n      #       glob: \"**/Chart.yaml\"\n      #       command: [sh, -c, find . -name env.yaml]\n\n  # -- Provide one or multiple [external cluster credentials]\n  # @default -- `{}` (See [values.yaml])\n  ## Ref:\n  ## - https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/#clusters\n  ## - https://argo-cd.readthedocs.io/en/stable/operator-manual/security/#external-cluster-credentials\n  ## - https://argo-cd.readthedocs.io/en/stable/user-guide/projects/#project-scoped-repositories-and-clusters\n  clusterCredentials: {}\n    # mycluster:\n    #   server: https://mycluster.example.com\n    #   labels: {}\n    #   annotations: {}\n    #   config:\n    #     bearerToken: \"\u003cauthentication token\u003e\"\n    #     tlsClientConfig:\n    #       insecure: false\n    #       caData: \"\u003cbase64 encoded certificate\u003e\"\n    # mycluster2:\n    #   server: https://mycluster2.example.com\n    #   labels: {}\n    #   annotations: {}\n    #   namespaces: namespace1,namespace2\n    #   clusterResources: true\n    #   config:\n    #     bearerToken: \"\u003cauthentication token\u003e\"\n    #     tlsClientConfig:\n    #       insecure: false\n    #       caData: \"\u003cbase64 encoded certificate\u003e\"\n    # mycluster3-project-scoped:\n    #   server: https://mycluster3.example.com\n    #   labels: {}\n    #   annotations: {}\n    #   project: my-project1\n    #   config:\n    #     bearerToken: \"\u003cauthentication token\u003e\"\n    #     tlsClientConfig:\n    #       insecure: false\n    #       caData: \"\u003cbase64 encoded certificate\u003e\"\n    # mycluster4-sharded:\n    #   shard: 1\n    #   server: https://mycluster4.example.com\n    #   labels: {}\n    #   annotations: {}\n    #   config:\n    #     bearerToken: \"\u003cauthentication token\u003e\"\n    #     tlsClientConfig:\n    #       insecure: false\n    #       caData: \"\u003cbase64 encoded certificate\u003e\"\n\n  # -- Repository credentials to be used as Templates for other repos\n  ## Creates a secret for each key/value specified below to create repository credentials\n  credentialTemplates: {}\n    # github-enterprise-creds-1:\n    #   url: https://github.com/argoproj\n    #   githubAppID: 1\n    #   githubAppInstallationID: 2\n    #   githubAppEnterpriseBaseUrl: https://ghe.example.com/api/v3\n    #   githubAppPrivateKey: |\n    #     -----BEGIN OPENSSH PRIVATE KEY-----\n    #     ...\n    #     -----END OPENSSH PRIVATE KEY-----\n    # https-creds:\n    #   url: https://github.com/argoproj\n    #   password: my-password\n    #   username: my-username\n    # ssh-creds:\n    #  url: git@github.com:argoproj-labs\n    #  sshPrivateKey: |\n    #    -----BEGIN OPENSSH PRIVATE KEY-----\n    #    ...\n    #    -----END OPENSSH PRIVATE KEY-----\n\n  # -- Annotations to be added to `configs.credentialTemplates` Secret\n  credentialTemplatesAnnotations: {}\n\n  # -- Repositories list to be used by applications\n  ## Creates a secret for each key/value specified below to create repositories\n  ## Note: the last example in the list would use a repository credential template, configured under \"configs.credentialTemplates\".\n  repositories: {}\n    # istio-helm-repo:\n    #   url: https://storage.googleapis.com/istio-prerelease/daily-build/master-latest-daily/charts\n    #   name: istio.io\n    #   type: helm\n    # private-helm-repo:\n    #   url: https://my-private-chart-repo.internal\n    #   name: private-repo\n    #   type: helm\n    #   password: my-password\n    #   username: my-username\n    # private-repo:\n    #   url: https://github.com/argoproj/private-repo\n\n  # -- Annotations to be added to `configs.repositories` Secret\n  repositoriesAnnotations: {}\n\n  # Argo CD sensitive data\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#sensitive-data-and-sso-client-secrets\n  secret:\n    # -- Create the argocd-secret\n    createSecret: true\n    # -- Labels to be added to argocd-secret\n    labels: {}\n    # -- Annotations to be added to argocd-secret\n    annotations: {}\n\n    # -- Shared secret for authenticating GitHub webhook events\n    githubSecret: \"\"\n    # -- Shared secret for authenticating GitLab webhook events\n    gitlabSecret: \"\"\n    # -- Shared secret for authenticating BitbucketServer webhook events\n    bitbucketServerSecret: \"\"\n    # -- UUID for authenticating Bitbucket webhook events\n    bitbucketUUID: \"\"\n    # -- Shared secret for authenticating Gogs webhook events\n    gogsSecret: \"\"\n    ## Azure DevOps\n    azureDevops:\n      # -- Shared secret username for authenticating Azure DevOps webhook events\n      username: \"\"\n      # -- Shared secret password for authenticating Azure DevOps webhook events\n      password: \"\"\n\n    # -- add additional secrets to be added to argocd-secret\n    ## Custom secrets. Useful for injecting SSO secrets into environment variables.\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#sensitive-data-and-sso-client-secrets\n    ## Note that all values must be non-empty.\n    extra:\n      {}\n      # LDAP_PASSWORD: \"mypassword\"\n\n    # -- Bcrypt hashed admin password\n    ## Argo expects the password in the secret to be bcrypt hashed. You can create this hash with\n    ## `htpasswd -nbBC 10 \"\" $ARGO_PWD | tr -d ':\\n' | sed 's/$2y/$2a/'`\n    argocdServerAdminPassword: \"\"\n    # -- Admin password modification time. Eg. `\"2006-01-02T15:04:05Z\"`\n    # @default -- `\"\"` (defaults to current time)\n    argocdServerAdminPasswordMtime: \"\"\n\n  # -- Define custom [CSS styles] for your argo instance.\n  # This setting will automatically mount the provided CSS and reference it in the argo configuration.\n  # @default -- `\"\"` (See [values.yaml])\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/custom-styles/\n  styles: \"\"\n  # styles: |\n  #  .sidebar {\n  #    background: linear-gradient(to bottom, #999, #777, #333, #222, #111);\n  #  }\n\n# -- Array of extra K8s manifests to deploy\n## Note: Supports use of custom Helm templates\nextraObjects: []\n  # - apiVersion: secrets-store.csi.x-k8s.io/v1\n  #   kind: SecretProviderClass\n  #   metadata:\n  #     name: argocd-secrets-store\n  #   spec:\n  #     provider: aws\n  #     parameters:\n  #       objects: |\n  #         - objectName: \"argocd\"\n  #           objectType: \"secretsmanager\"\n  #           jmesPath:\n  #               - path: \"client_id\"\n  #                 objectAlias: \"client_id\"\n  #               - path: \"client_secret\"\n  #                 objectAlias: \"client_secret\"\n  #     secretObjects:\n  #     - data:\n  #       - key: client_id\n  #         objectName: client_id\n  #       - key: client_secret\n  #         objectName: client_secret\n  #       secretName: argocd-secrets-store\n  #       type: Opaque\n  #       labels:\n  #         app.kubernetes.io/part-of: argocd\n\n## Application controller\ncontroller:\n  # -- Application controller name string\n  name: application-controller\n\n  # -- The number of application controller pods to run.\n  # Additional replicas will cause sharding of managed clusters across number of replicas.\n  ## With dynamic cluster distribution turned on, sharding of the clusters will gracefully\n  ## rebalance if the number of replica's changes or one becomes unhealthy. (alpha)\n  replicas: 1\n\n  # -- Enable dynamic cluster distribution (alpha)\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/dynamic-cluster-distribution\n  ## This is done using a deployment instead of a statefulSet\n  ## When replicas are added or removed, the sharding algorithm is re-run to ensure that the\n  ## clusters are distributed according to the algorithm. If the algorithm is well-balanced,\n  ## like round-robin, then the shards will be well-balanced.\n  dynamicClusterDistribution: false\n\n  # -- Runtime class name for the application controller\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  # -- Application controller heartbeat time\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/dynamic-cluster-distribution/#working-of-dynamic-distribution\n  heartbeatTime: 10\n\n  # -- Maximum number of controller revisions that will be maintained in StatefulSet history\n  revisionHistoryLimit: 5\n\n  ## Application controller Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the application controller\n    enabled: false\n    # -- Labels to be added to application controller pdb\n    labels: {}\n    # -- Annotations to be added to application controller pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailable after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `controller.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## Application controller image\n  image:\n    # -- Repository to use for the application controller\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the application controller\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the application controller\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- Additional command line arguments to pass to application controller\n  extraArgs: []\n\n  # -- Environment variables to pass to application controller\n  env: []\n\n  # -- envFrom to pass to application controller\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Additional containers to be added to the application controller pod\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n\n  # -- Init containers to add to the application controller pod\n  ## If your target Kubernetes cluster(s) require a custom credential (exec) plugin\n  ## you could use this (and the same in the server pod) to provide such executable\n  ## Ref: https://kubernetes.io/docs/reference/access-authn-authz/authentication/#client-go-credential-plugins\n  ## Note: Supports use of custom Helm templates\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO kubelogin.zip https://github.com/Azure/kubelogin/releases/download/v0.0.25/kubelogin-linux-amd64.zip \u0026\u0026\n  #        unzip kubelogin.zip \u0026\u0026 mv bin/linux_amd64/kubelogin /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n\n  # -- Additional volumeMounts to the application controller main container\n  volumeMounts: []\n  #  - mountPath: /usr/local/bin/kubelogin\n  #    name: custom-tools\n  #    subPath: kubelogin\n\n  # -- Additional volumes to the application controller pod\n  volumes: []\n  #  - name: custom-tools\n  #    emptyDir: {}\n\n  ## Application controller emptyDir volumes\n  emptyDir:\n    # -- EmptyDir size limit for application controller\n    # @default -- `\"\"` (defaults not set if not specified i.e. no size limit)\n    sizeLimit: \"\"\n    # sizeLimit: \"1Gi\"\n\n  # -- Annotations for the application controller StatefulSet\n  statefulsetAnnotations: {}\n\n  # -- Annotations for the application controller Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations to be added to application controller pods\n  podAnnotations: {}\n\n  # -- Labels to be added to application controller pods\n  podLabels: {}\n\n  # -- Resource limits and requests for the application controller pods\n  resources: {}\n  #  limits:\n  #    cpu: 500m\n  #    memory: 512Mi\n  #  requests:\n  #    cpu: 250m\n  #    memory: 256Mi\n\n  # Application controller container ports\n  containerPorts:\n    # -- Metrics container port\n    metrics: 8082\n\n  # -- Host Network for application controller pods\n  hostNetwork: false\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for application controller pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- Application controller container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    seccompProfile:\n      type: RuntimeDefault\n    capabilities:\n      drop:\n      - ALL\n\n  # Readiness probe for application controller\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- Priority class for the application controller pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules to the deployment\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the application controller\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  serviceAccount:\n    # -- Create a service account for the application controller\n    create: true\n    # -- Service account name\n    name: argocd-application-controller\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Labels applied to created service account\n    labels: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  ## Application controller metrics configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    # -- Prometheus ServiceMonitor scrapeTimeout. If empty, Prometheus uses the global scrape timeout unless it is less than the target's scrape interval value in which the latter is used.\n    scrapeTimeout: \"\"\n    applicationLabels:\n      # -- Enables additional labels in argocd_app_labels metric\n      enabled: false\n      # -- Additional labels\n      labels: []\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: \"\"\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8082\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n    rules:\n      # -- Deploy a PrometheusRule for the application controller\n      enabled: false\n      # -- PrometheusRule namespace\n      namespace: \"\" # \"monitoring\"\n      # -- PrometheusRule selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- PrometheusRule labels\n      additionalLabels: {}\n      # -- PrometheusRule annotations\n      annotations: {}\n\n      # -- PrometheusRule.Spec for the application controller\n      spec: []\n      # - alert: ArgoAppMissing\n      #   expr: |\n      #     absent(argocd_app_info) == 1\n      #   for: 15m\n      #   labels:\n      #     severity: critical\n      #   annotations:\n      #     summary: \"[Argo CD] No reported applications\"\n      #     description: \u003e\n      #       Argo CD has not reported any applications data for the past 15 minutes which\n      #       means that it must be down or not functioning properly.  This needs to be\n      #       resolved for this cloud to continue to maintain state.\n      # - alert: ArgoAppNotSynced\n      #   expr: |\n      #     argocd_app_info{sync_status!=\"Synced\"} == 1\n      #   for: 12h\n      #   labels:\n      #     severity: warning\n      #   annotations:\n      #     summary: \"[{{`{{$labels.name}}`}}] Application not synchronized\"\n      #     description: \u003e\n      #       The application [{{`{{$labels.name}}`}} has not been synchronized for over\n      #       12 hours which means that the state of this cloud has drifted away from the\n      #       state inside Git.\n\n  ## Enable this and set the rules: to whatever custom rules you want for the Cluster Role resource.\n  ## Defaults to off\n  clusterRoleRules:\n    # -- Enable custom rules for the application controller's ClusterRole resource\n    enabled: false\n    # -- List of custom rules for the application controller's ClusterRole resource\n    rules: []\n\n## Dex\ndex:\n  # -- Enable dex\n  enabled: true\n  # -- Dex name\n  name: dex-server\n\n  # -- Additional command line arguments to pass to the Dex server\n  extraArgs: []\n\n  # -- Runtime class name for Dex\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n\n  ## Dex Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the Dex server\n    enabled: false\n    # -- Labels to be added to Dex server pdb\n    labels: {}\n    # -- Annotations to be added to Dex server pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailble after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `dex.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## Dex image\n  image:\n    # -- Dex image repository\n    repository: ghcr.io/dexidp/dex\n    # -- Dex image tag\n    tag: v2.42.0\n    # -- Dex imagePullPolicy\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # Argo CD init image that creates Dex config\n  initImage:\n    # -- Argo CD init image repository\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Argo CD init image tag\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Argo CD init image imagePullPolicy\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n    # -- Argo CD init image resources\n    # @default -- `{}` (defaults to dex.resources)\n    resources: {}\n    #  requests:\n    #    cpu: 5m\n    #    memory: 96Mi\n    #  limits:\n    #    cpu: 10m\n    #    memory: 144Mi\n\n  # -- Environment variables to pass to the Dex server\n  env: []\n\n  # -- envFrom to pass to the Dex server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Additional containers to be added to the dex pod\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n\n  # -- Init containers to add to the dex pod\n  ## Note: Supports use of custom Helm templates\n  initContainers: []\n\n  # -- Additional volumeMounts to the dex main container\n  volumeMounts: []\n\n  # -- Additional volumes to the dex pod\n  volumes: []\n\n  ## Dex server emptyDir volumes\n  emptyDir:\n    # -- EmptyDir size limit for Dex server\n    # @default -- `\"\"` (defaults not set if not specified i.e. no size limit)\n    sizeLimit: \"\"\n    # sizeLimit: \"1Gi\"\n\n  # TLS certificate configuration via Secret\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/tls/#configuring-tls-to-argocd-dex-server\n  ## Note: Issuing certificates via cert-manager in not supported right now because it's not possible to restart Dex automatically without extra controllers.\n  certificateSecret:\n    # -- Create argocd-dex-server-tls secret\n    enabled: false\n    # -- Labels to be added to argocd-dex-server-tls secret\n    labels: {}\n    # -- Annotations to be added to argocd-dex-server-tls secret\n    annotations: {}\n    # -- Certificate authority. Required for self-signed certificates.\n    ca: ''\n    # -- Certificate private key\n    key: ''\n    # -- Certificate data. Must contain SANs of Dex service (ie: argocd-dex-server, argocd-dex-server.argo-cd.svc)\n    crt: ''\n\n  # -- Annotations to be added to the Dex server Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations to be added to the Dex server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to the Dex server pods\n  podLabels: {}\n\n  # -- Resource limits and requests for dex\n  resources: {}\n  #  limits:\n  #    cpu: 50m\n  #    memory: 64Mi\n  #  requests:\n  #    cpu: 10m\n  #    memory: 32Mi\n\n  # Dex container ports\n  # NOTE: These ports are currently hardcoded and cannot be changed\n  containerPorts:\n    # -- HTTP container port\n    http: 5556\n    # -- gRPC container port\n    grpc: 5557\n    # -- Metrics container port\n    metrics: 5558\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for Dex server pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- Dex container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    seccompProfile:\n      type: RuntimeDefault\n    capabilities:\n      drop:\n      - ALL\n\n  ## Probes for Dex server\n  ## Supported from Dex \u003e= 2.28.0\n  livenessProbe:\n    # -- Enable Kubernetes liveness probe for Dex \u003e= 2.28.0\n    enabled: false\n    # -- Http path to use for the liveness probe\n    httpPath: /healthz/live\n    # -- Http port to use for the liveness probe\n    httpPort: metrics\n    # -- Scheme to use for for the liveness probe (can be HTTP or HTTPS)\n    httpScheme: HTTP\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  readinessProbe:\n    # -- Enable Kubernetes readiness probe for Dex \u003e= 2.28.0\n    enabled: false\n    # -- Http path to use for the readiness probe\n    httpPath: /healthz/ready\n    # -- Http port to use for the readiness probe\n    httpPort: metrics\n    # -- Scheme to use for for the liveness probe (can be HTTP or HTTPS)\n    httpScheme: HTTP\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  serviceAccount:\n    # -- Create dex service account\n    create: true\n    # -- Dex service account name\n    name: argocd-dex-server\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Service port for HTTP access\n  servicePortHttp: 5556\n  # -- Service port name for HTTP access\n  servicePortHttpName: http\n  # -- Service port for gRPC access\n  servicePortGrpc: 5557\n  # -- Service port name for gRPC access\n  servicePortGrpcName: grpc\n  # -- Service port for metrics access\n  servicePortMetrics: 5558\n\n  # -- Priority class for the dex pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules to the deployment\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to dex\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy to be added to the Dex server Deployment\n  deploymentStrategy: {}\n    # type: RollingUpdate\n    # rollingUpdate:\n    #   maxSurge: 25%\n    #   maxUnavailable: 25%\n\n  # -- Dex log format. Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logFormat: \"\"\n  # -- Dex log level. One of: `debug`, `info`, `warn`, `error`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logLevel: \"\"\n\n## Redis\nredis:\n  # -- Enable redis\n  enabled: true\n  # -- Redis name\n  name: redis\n\n  # -- Runtime class name for redis\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  ## Redis Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the Redis\n    enabled: false\n    # -- Labels to be added to Redis pdb\n    labels: {}\n    # -- Annotations to be added to Redis pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailble after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `redis.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## Redis image\n  image:\n    # -- Redis repository\n    repository: public.ecr.aws/docker/library/redis\n    # -- Redis tag\n    tag: 7.4.2-alpine\n    # -- Redis image pull policy\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  ## Prometheus redis-exporter sidecar\n  exporter:\n    # -- Enable Prometheus redis-exporter sidecar\n    enabled: false\n    # -- Environment variables to pass to the Redis exporter\n    env: []\n    ## Prometheus redis-exporter image\n    image:\n      # -- Repository to use for the redis-exporter\n      repository: public.ecr.aws/bitnami/redis-exporter\n      # -- Tag to use for the redis-exporter\n      tag: 1.67.0\n      # -- Image pull policy for the redis-exporter\n      # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n      imagePullPolicy: \"\"\n\n    # -- Redis exporter security context\n    # @default -- See [values.yaml]\n    containerSecurityContext:\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n      allowPrivilegeEscalation: false\n      seccompProfile:\n        type: RuntimeDefault\n      capabilities:\n        drop:\n        - ALL\n\n    ## Probes for Redis exporter (optional)\n    ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n    readinessProbe:\n      # -- Enable Kubernetes liveness probe for Redis exporter (optional)\n      enabled: false\n      # -- Number of seconds after the container has started before [probe] is initiated\n      initialDelaySeconds: 30\n      # -- How often (in seconds) to perform the [probe]\n      periodSeconds: 15\n      # -- Number of seconds after which the [probe] times out\n      timeoutSeconds: 15\n      # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n      successThreshold: 1\n      # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n      failureThreshold: 5\n    livenessProbe:\n      # -- Enable Kubernetes liveness probe for Redis exporter\n      enabled: false\n      # -- Number of seconds after the container has started before [probe] is initiated\n      initialDelaySeconds: 30\n      # -- How often (in seconds) to perform the [probe]\n      periodSeconds: 15\n      # -- Number of seconds after which the [probe] times out\n      timeoutSeconds: 15\n      # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n      successThreshold: 1\n      # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n      failureThreshold: 5\n\n    # -- Resource limits and requests for redis-exporter sidecar\n    resources: {}\n      # limits:\n      #   cpu: 50m\n      #   memory: 64Mi\n      # requests:\n      #   cpu: 10m\n      #   memory: 32Mi\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- Additional command line arguments to pass to redis-server\n  extraArgs: []\n  # - --bind\n  # - \"0.0.0.0\"\n\n  # -- Environment variables to pass to the Redis server\n  env: []\n\n  # -- envFrom to pass to the Redis server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  ## Probes for Redis server (optional)\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Enable Kubernetes liveness probe for Redis server\n    enabled: false\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 30\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 15\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 15\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 5\n  livenessProbe:\n    # -- Enable Kubernetes liveness probe for Redis server\n    enabled: false\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 30\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 15\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 15\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 5\n\n  # -- Additional containers to be added to the redis pod\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n\n  # -- Init containers to add to the redis pod\n  ## Note: Supports use of custom Helm templates\n  initContainers: []\n\n  # -- Additional volumeMounts to the redis container\n  volumeMounts: []\n\n  # -- Additional volumes to the redis pod\n  volumes: []\n\n  # -- Annotations to be added to the Redis server Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations to be added to the Redis server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to the Redis server pods\n  podLabels: {}\n\n  # -- Resource limits and requests for redis\n  resources: {}\n  #  limits:\n  #    cpu: 200m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  # -- Redis pod-level security context\n  # @default -- See [values.yaml]\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 999\n    seccompProfile:\n      type: RuntimeDefault\n\n  # Redis container ports\n  containerPorts:\n    # -- Redis container port\n    redis: 6379\n    # -- Metrics container port\n    metrics: 9121\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for Redis server pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- Redis container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    capabilities:\n      drop:\n      - ALL\n\n  # -- Redis service port\n  servicePort: 6379\n\n  # -- Priority class for redis pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules to the deployment\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to redis\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  serviceAccount:\n    # -- Create a service account for the redis pod\n    create: false\n    # -- Service account name for redis pod\n    name: \"\"\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: false\n\n  service:\n    # -- Redis service annotations\n    annotations: {}\n    # -- Additional redis service labels\n    labels: {}\n\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n\n    # Redis metrics service configuration\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: None\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 9121\n      # -- Metrics service port name\n      portName: http-metrics\n\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Interval at which metrics should be scraped\n      interval: 30s\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n\n## Redis-HA subchart replaces custom redis deployment when `redis-ha.enabled=true`\n# Ref: https://github.com/DandyDeveloper/charts/blob/master/charts/redis-ha/values.yaml\nredis-ha:\n  # -- Enables the Redis HA subchart and disables the custom Redis single node deployment\n  enabled: false\n  ## Redis image\n  image:\n    # -- Redis repository\n    repository: public.ecr.aws/docker/library/redis\n    # -- Redis tag\n    tag: 7.4.2-alpine\n  ## Prometheus redis-exporter sidecar\n  exporter:\n    # -- Enable Prometheus redis-exporter sidecar\n    enabled: false\n    # -- Repository to use for the redis-exporter\n    image: public.ecr.aws/bitnami/redis-exporter\n    # -- Tag to use for the redis-exporter\n    tag: 1.58.0\n  persistentVolume:\n    # -- Configures persistence on Redis nodes\n    enabled: false\n  ## Redis specific configuration options\n  redis:\n    # -- Redis convention for naming the cluster group: must match `^[\\\\w-\\\\.]+$` and can be templated\n    masterGroupName: argocd\n    # -- Any valid redis config options in this section will be applied to each server (see `redis-ha` chart)\n    # @default -- See [values.yaml]\n    config:\n      # -- Will save the DB if both the given number of seconds and the given number of write operations against the DB occurred. `\"\"`  is disabled\n      # @default -- `'\"\"'`\n      save: '\"\"'\n  ## Enables a HA Proxy for better LoadBalancing / Sentinel Master support. Automatically proxies to Redis master.\n  haproxy:\n    # -- Enabled HAProxy LoadBalancing/Proxy\n    enabled: true\n    # --  Custom labels for the haproxy pod. This is relevant for Argo CD CLI.\n    labels:\n      app.kubernetes.io/name: argocd-redis-ha-haproxy\n    metrics:\n      # -- HAProxy enable prometheus metric scraping\n      enabled: true\n    # -- Whether the haproxy pods should be forced to run on separate nodes.\n    hardAntiAffinity: true\n    # -- Additional affinities to add to the haproxy pods.\n    additionalAffinities: {}\n    # -- Assign custom [affinity] rules to the haproxy pods.\n    affinity: |\n\n    # -- [Tolerations] for use with node taints for haproxy pods.\n    tolerations: []\n    # -- HAProxy container-level security context\n    # @default -- See [values.yaml]\n    containerSecurityContext:\n      readOnlyRootFilesystem: true\n\n  # -- Configures redis-ha with AUTH\n  auth: true\n  # -- Existing Secret to use for redis-ha authentication.\n  # By default the redis-secret-init Job is generating this Secret.\n  existingSecret: argocd-redis\n\n  # -- Whether the Redis server pods should be forced to run on separate nodes.\n  hardAntiAffinity: true\n\n  # -- Additional affinities to add to the Redis server pods.\n  additionalAffinities: {}\n\n  # -- Assign custom [affinity] rules to the Redis pods.\n  affinity: |\n\n  # -- [Tolerations] for use with node taints for Redis pods.\n  tolerations: []\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the Redis pods.\n  ## https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  topologySpreadConstraints:\n    # -- Enable Redis HA topology spread constraints\n    enabled: false\n    # -- Max skew of pods tolerated\n    # @default -- `\"\"` (defaults to `1`)\n    maxSkew: \"\"\n    # -- Topology key for spread\n    # @default -- `\"\"` (defaults to `topology.kubernetes.io/zone`)\n    topologyKey: \"\"\n    # -- Enforcement policy, hard or soft\n    # @default -- `\"\"` (defaults to `ScheduleAnyway`)\n    whenUnsatisfiable: \"\"\n  # -- Redis HA statefulset container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    readOnlyRootFilesystem: true\n\n# External Redis parameters\nexternalRedis:\n  # -- External Redis server host\n  host: \"\"\n  # -- External Redis username\n  username: \"\"\n  # -- External Redis password\n  password: \"\"\n  # -- External Redis server port\n  port: 6379\n  # -- The name of an existing secret with Redis (must contain key `redis-password`) and Sentinel credentials.\n  # When it's set, the `externalRedis.password` parameter is ignored\n  existingSecret: \"\"\n  # -- External Redis Secret annotations\n  secretAnnotations: {}\n\nredisSecretInit:\n  # -- Enable Redis secret initialization. If disabled, secret must be provisioned by alternative methods\n  enabled: true\n  # -- Redis secret-init name\n  name: redis-secret-init\n\n  image:\n    # -- Repository to use for the Redis secret-init Job\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\" # defaults to global.image.repository\n    # -- Tag to use for the Redis secret-init Job\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\" # defaults to global.image.tag\n    # -- Image pull policy for the Redis secret-init Job\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\" # IfNotPresent\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- Annotations to be added to the Redis secret-init Job\n  jobAnnotations: {}\n\n  # -- Annotations to be added to the Redis secret-init Job\n  podAnnotations: {}\n\n  # -- Labels to be added to the Redis secret-init Job\n  podLabels: {}\n\n  # -- Resource limits and requests for Redis secret-init Job\n  resources: {}\n  #  limits:\n  #    cpu: 200m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  # -- Application controller container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    allowPrivilegeEscalation: false\n    capabilities:\n      drop:\n        - ALL\n    readOnlyRootFilesystem: true\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n\n  # -- Redis secret-init Job pod-level security context\n  securityContext: {}\n\n  serviceAccount:\n    # -- Create a service account for the redis pod\n    create: true\n    # -- Service account name for redis pod\n    name: \"\"\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Priority class for Redis secret-init Job\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # -- Assign custom [affinity] rules to the Redis secret-init Job\n  affinity: {}\n\n  # -- Node selector to be added to the Redis secret-init Job\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- Tolerations to be added to the Redis secret-init Job\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n## Server\nserver:\n  # -- Argo CD server name\n  name: server\n\n  # -- The number of server pods to run\n  replicas: 1\n\n  # -- Runtime class name for the Argo CD server\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  ## Argo CD server Horizontal Pod Autoscaler\n  autoscaling:\n    # -- Enable Horizontal Pod Autoscaler ([HPA]) for the Argo CD server\n    enabled: false\n    # -- Minimum number of replicas for the Argo CD server [HPA]\n    minReplicas: 1\n    # -- Maximum number of replicas for the Argo CD server [HPA]\n    maxReplicas: 5\n    # -- Average CPU utilization percentage for the Argo CD server [HPA]\n    targetCPUUtilizationPercentage: 50\n    # -- Average memory utilization percentage for the Argo CD server [HPA]\n    targetMemoryUtilizationPercentage: 50\n    # -- Configures the scaling behavior of the target in both Up and Down directions.\n    behavior: {}\n      # scaleDown:\n      #  stabilizationWindowSeconds: 300\n      #  policies:\n      #   - type: Pods\n      #     value: 1\n      #     periodSeconds: 180\n      # scaleUp:\n      #   stabilizationWindowSeconds: 300\n      #   policies:\n      #   - type: Pods\n      #     value: 2\n      #     periodSeconds: 60\n    # -- Configures custom HPA metrics for the Argo CD server\n    # Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\n    metrics: []\n\n  ## Argo CD server Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the Argo CD server\n    enabled: false\n    # -- Labels to be added to Argo CD server pdb\n    labels: {}\n    # -- Annotations to be added to Argo CD server pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailable after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `server.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## Argo CD server image\n  image:\n    # -- Repository to use for the Argo CD server\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\" # defaults to global.image.repository\n    # -- Tag to use for the Argo CD server\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\" # defaults to global.image.tag\n    # -- Image pull policy for the Argo CD server\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\" # IfNotPresent\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- Additional command line arguments to pass to Argo CD server\n  extraArgs: []\n\n  # -- Environment variables to pass to Argo CD server\n  env: []\n\n  # -- envFrom to pass to Argo CD server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Specify postStart and preStop lifecycle hooks for your argo-cd-server container\n  lifecycle: {}\n\n  ## Argo CD extensions\n  ## This function in tech preview stage, do expect instability or breaking changes in newer versions.\n  ## Ref: https://github.com/argoproj-labs/argocd-extension-installer\n  ## When you enable extensions, you need to configure RBAC of logged in Argo CD user.\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/rbac/#the-extensions-resource\n  extensions:\n    # -- Enable support for Argo CD extensions\n    enabled: false\n\n    ## Argo CD extension installer image\n    image:\n      # -- Repository to use for extension installer image\n      repository: \"quay.io/argoprojlabs/argocd-extension-installer\"\n      # -- Tag to use for extension installer image\n      tag: \"v0.0.8\"\n      # -- Image pull policy for extensions\n      # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n      imagePullPolicy: \"\"\n\n    # -- Extensions for Argo CD\n    # @default -- `[]` (See [values.yaml])\n    ## Ref: https://github.com/argoproj-labs/argocd-extension-metrics#install-ui-extension\n    extensionList: []\n    #  - name: extension-metrics\n    #    env:\n    #      - name: EXTENSION_URL\n    #        value: https://github.com/argoproj-labs/argocd-extension-metrics/releases/download/v1.0.0/extension.tar.gz\n    #      - name: EXTENSION_CHECKSUM_URL\n    #        value: https://github.com/argoproj-labs/argocd-extension-metrics/releases/download/v1.0.0/extension_checksums.txt\n\n    # -- Server UI extensions container-level security context\n    # @default -- See [values.yaml]\n    containerSecurityContext:\n      runAsNonRoot: true\n      readOnlyRootFilesystem: true\n      allowPrivilegeEscalation: false\n      runAsUser: 1000\n      seccompProfile:\n        type: RuntimeDefault\n      capabilities:\n        drop:\n        - ALL\n\n    # -- Resource limits and requests for the argocd-extensions container\n    resources: {}\n    #  limits:\n    #    cpu: 50m\n    #    memory: 128Mi\n    #  requests:\n    #    cpu: 10m\n    #    memory: 64Mi\n\n  # -- Additional containers to be added to the server pod\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n  # - name: my-sidecar\n  #   image: nginx:latest\n  # - name: lemonldap-ng-controller\n  #   image: lemonldapng/lemonldap-ng-controller:0.2.0\n  #   args:\n  #     - /lemonldap-ng-controller\n  #     - --alsologtostderr\n  #     - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n  #   env:\n  #     - name: POD_NAME\n  #       valueFrom:\n  #         fieldRef:\n  #           fieldPath: metadata.name\n  #     - name: POD_NAMESPACE\n  #       valueFrom:\n  #         fieldRef:\n  #           fieldPath: metadata.namespace\n  #   volumeMounts:\n  #   - name: copy-portal-skins\n  #     mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n  # -- Init containers to add to the server pod\n  ## If your target Kubernetes cluster(s) require a custom credential (exec) plugin\n  ## you could use this (and the same in the application controller pod) to provide such executable\n  ## Ref: https://kubernetes.io/docs/reference/access-authn-authz/authentication/#client-go-credential-plugins\n  initContainers: []\n  #  - name: download-tools\n  #    image: alpine:3\n  #    command: [sh, -c]\n  #    args:\n  #      - wget -qO kubelogin.zip https://github.com/Azure/kubelogin/releases/download/v0.0.25/kubelogin-linux-amd64.zip \u0026\u0026\n  #        unzip kubelogin.zip \u0026\u0026 mv bin/linux_amd64/kubelogin /custom-tools/\n  #    volumeMounts:\n  #      - mountPath: /custom-tools\n  #        name: custom-tools\n\n  # -- Additional volumeMounts to the server main container\n  volumeMounts: []\n  #  - mountPath: /usr/local/bin/kubelogin\n  #    name: custom-tools\n  #    subPath: kubelogin\n\n  # -- Additional volumes to the server pod\n  volumes: []\n  #  - name: custom-tools\n  #    emptyDir: {}\n\n  ## Argo CD server emptyDir volumes\n  emptyDir:\n    # -- EmptyDir size limit for the Argo CD server\n    # @default -- `\"\"` (defaults not set if not specified i.e. no size limit)\n    sizeLimit: \"\"\n    # sizeLimit: \"1Gi\"\n\n  # -- Annotations to be added to server Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations to be added to server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to server pods\n  podLabels: {}\n\n  # -- Resource limits and requests for the Argo CD server\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 50m\n  #    memory: 64Mi\n\n  # Server container ports\n  containerPorts:\n    # -- Server container port\n    server: 8080\n    # -- Metrics container port\n    metrics: 8083\n\n  # -- Host Network for Server pods\n  hostNetwork: false\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for Server pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- Server container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    seccompProfile:\n      type: RuntimeDefault\n    capabilities:\n      drop:\n      - ALL\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  livenessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- Priority class for the Argo CD server pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules to the deployment\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the Argo CD server\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy to be added to the server Deployment\n  deploymentStrategy: {}\n    # type: RollingUpdate\n    # rollingUpdate:\n    #   maxSurge: 25%\n    #   maxUnavailable: 25%\n\n  # TLS certificate configuration via cert-manager\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/tls/#tls-certificates-used-by-argocd-server\n  certificate:\n    # -- Deploy a Certificate resource (requires cert-manager)\n    enabled: false\n    # -- Certificate primary domain (commonName)\n    # @default -- `\"\"` (defaults to global.domain)\n    domain: \"\"\n    # -- Certificate Subject Alternate Names (SANs)\n    additionalHosts: []\n    # -- The requested 'duration' (i.e. lifetime) of the certificate.\n    # @default -- `\"\"` (defaults to 2160h = 90d if not specified)\n    ## Ref: https://cert-manager.io/docs/usage/certificate/#renewal\n    duration: \"\"\n    # -- How long before the expiry a certificate should be renewed.\n    # @default -- `\"\"` (defaults to 360h = 15d if not specified)\n    ## Ref: https://cert-manager.io/docs/usage/certificate/#renewal\n    renewBefore: \"\"\n    # Certificate issuer\n    ## Ref: https://cert-manager.io/docs/concepts/issuer\n    issuer:\n      # -- Certificate issuer group. Set if using an external issuer. Eg. `cert-manager.io`\n      group: \"\"\n      # -- Certificate issuer kind. Either `Issuer` or `ClusterIssuer`\n      kind: \"\"\n      # -- Certificate issuer name. Eg. `letsencrypt`\n      name: \"\"\n    # Private key of the certificate\n    privateKey:\n      # -- Rotation policy of private key when certificate is re-issued. Either: `Never` or `Always`\n      rotationPolicy: Never\n      # -- The private key cryptography standards (PKCS) encoding for private key. Either: `PCKS1` or `PKCS8`\n      encoding: PKCS1\n      # -- Algorithm used to generate certificate private key. One of: `RSA`, `Ed25519` or `ECDSA`\n      algorithm: RSA\n      # -- Key bit size of the private key. If algorithm is set to `Ed25519`, size is ignored.\n      size: 2048\n    # -- Annotations to be applied to the Server Certificate\n    annotations: {}\n    # -- Usages for the certificate\n    ### Ref: https://cert-manager.io/docs/reference/api-docs/#cert-manager.io/v1.KeyUsage\n    usages: []\n    # -- Annotations that allow the certificate to be composed from data residing in existing Kubernetes Resources\n    secretTemplateAnnotations: {}\n\n  # TLS certificate configuration via Secret\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/tls/#tls-certificates-used-by-argocd-server\n  certificateSecret:\n    # -- Create argocd-server-tls secret\n    enabled: false\n    # -- Annotations to be added to argocd-server-tls secret\n    annotations: {}\n    # -- Labels to be added to argocd-server-tls secret\n    labels: {}\n    # -- Private Key of the certificate\n    key: ''\n    # -- Certificate data\n    crt: ''\n\n  ## Server service configuration\n  service:\n    # -- Server service annotations\n    annotations: {}\n    # -- Server service labels\n    labels: {}\n    # -- Server service type\n    type: ClusterIP\n    # -- Server service http port for NodePort service type (only if `server.service.type` is set to \"NodePort\")\n    nodePortHttp: 30080\n    # -- Server service https port for NodePort service type (only if `server.service.type` is set to \"NodePort\")\n    nodePortHttps: 30443\n    # -- Server service http port\n    servicePortHttp: 80\n    # -- Server service https port\n    servicePortHttps: 443\n    # -- Server service http port name, can be used to route traffic via istio\n    servicePortHttpName: http\n    # -- Server service https port name, can be used to route traffic via istio\n    servicePortHttpsName: https\n    # -- Server service https port appProtocol\n    ## Ref: https://kubernetes.io/docs/concepts/services-networking/service/#application-protocol\n    servicePortHttpsAppProtocol: \"\"\n    # -- The class of the load balancer implementation\n    loadBalancerClass: \"\"\n    # -- LoadBalancer will get created with the IP specified in this field\n    loadBalancerIP: \"\"\n    # -- Source IP ranges to allow access to service from\n    ## EKS Ref: https://repost.aws/knowledge-center/eks-cidr-ip-address-loadbalancer\n    ## GKE Ref: https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview#limit-connectivity-ext-lb\n    loadBalancerSourceRanges: []\n    # -- Server service external IPs\n    externalIPs: []\n    # -- Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints\n    ## Ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n    externalTrafficPolicy: Cluster\n    # -- Used to maintain session affinity. Supports `ClientIP` and `None`\n    ## Ref: https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies\n    sessionAffinity: None\n\n  ## Server metrics service configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: \"\"\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8083\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus ServiceMonitor scrapeTimeout. If empty, Prometheus uses the global scrape timeout unless it is less than the target's scrape interval value in which the latter is used.\n      scrapeTimeout: \"\"\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\"  # monitoring\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  serviceAccount:\n    # -- Create server service account\n    create: true\n    # -- Server service account name\n    name: argocd-server\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Labels applied to created service account\n    labels: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # Argo CD server ingress configuration\n  ingress:\n    # -- Enable an ingress resource for the Argo CD server\n    enabled: true\n    # -- Specific implementation for ingress controller. One of `generic`, `aws` or `gke`\n    ## Additional configuration might be required in related configuration sections\n    controller: generic\n    # -- Additional ingress labels\n    labels: {}\n    # -- Additional ingress annotations\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-1-ssl-passthrough\n    annotations:\n      nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n      nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\n\n    # -- Defines which ingress controller will implement the resource\n    ingressClassName: \"nginx-internal\"\n\n    # -- Argo CD server hostname\n    # @default -- `\"\"` (defaults to global.domain)\n    hostname: \"argocd.example.com\"\n\n    # -- The path to Argo CD server\n    path: /\n\n    # -- Ingress path type. One of `Exact`, `Prefix` or `ImplementationSpecific`\n    pathType: Prefix\n\n    # -- Enable TLS configuration for the hostname defined at `server.ingress.hostname`\n    ## TLS certificate will be retrieved from a TLS secret `argocd-server-tls`\n    ## You can create this secret via `certificate` or `certificateSecret` option\n    tls: false\n\n    # -- The list of additional hostnames to be covered by ingress record\n    # @default -- `[]` (See [values.yaml])\n    extraHosts: []\n      # - name: argocd.example.com\n      #   path: /\n\n    # -- Additional ingress paths\n    # @default -- `[]` (See [values.yaml])\n    ## Note: Supports use of custom Helm templates\n    extraPaths: []\n      # - path: /*\n      #   pathType: Prefix\n      #   backend:\n      #     service:\n      #       name: ssl-redirect\n      #       port:\n      #         name: use-annotation\n\n    # -- Additional ingress rules\n    # @default -- `[]` (See [values.yaml])\n    ## Note: Supports use of custom Helm templates\n    extraRules: []\n      # - http:\n      #     paths:\n      #     - path: /\n      #       pathType: Prefix\n      #       backend:\n      #         service:\n      #           name: '{{ include \"argo-cd.server.fullname\" . }}'\n      #           port:\n      #             name: '{{ .Values.server.service.servicePortHttpsName }}'\n\n    # -- Additional TLS configuration\n    # @default -- `[]` (See [values.yaml])\n    extraTls: []\n      # - hosts:\n      #   - argocd.example.com\n      #   secretName: your-certificate-name\n\n    # AWS specific options for Application Load Balancer\n    # Applies only when `serv.ingress.controller` is set to `aws`\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#aws-application-load-balancers-albs-and-classic-elb-http-mode\n    aws:\n      # -- Backend protocol version for the AWS ALB gRPC service\n      ## This tells AWS to send traffic from the ALB using gRPC.\n      ## For more information: https://docs.aws.amazon.com/elasticloadbalancing/latest/application/target-group-health-checks.html#health-check-settings\n      backendProtocolVersion: GRPC\n      # -- Service type for the AWS ALB gRPC service\n      ## Can be of type NodePort or ClusterIP depending on which mode you are running.\n      ## Instance mode needs type NodePort, IP mode needs type ClusterIP\n      ## Ref: https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.2/how-it-works/#ingress-traffic\n      serviceType: NodePort\n\n    # Google specific options for Google Application Load Balancer\n    # Applies only when `server.ingress.controller` is set to `gke`\n    ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#google-cloud-load-balancers-with-kubernetes-ingress\n    gke:\n      # -- Google [BackendConfig] resource, for use with the GKE Ingress Controller\n      # @default -- `{}` (See [values.yaml])\n      ## Ref: https://cloud.google.com/kubernetes-engine/docs/how-to/ingress-features#configuring_ingress_features_through_frontendconfig_parameters\n      backendConfig: {}\n        # iap:\n        #  enabled: true\n        #  oauthclientCredentials:\n        #    secretName: argocd-secret\n\n      # -- Google [FrontendConfig] resource, for use with the GKE Ingress Controller\n      # @default -- `{}` (See [values.yaml])\n      ## Ref: https://cloud.google.com/kubernetes-engine/docs/how-to/ingress-features#configuring_ingress_features_through_frontendconfig_parameters\n      frontendConfig: {}\n        # redirectToHttps:\n        #   enabled: true\n        #   responseCodeName: RESPONSE_CODE\n\n      # Managed GKE certificate for ingress hostname\n      managedCertificate:\n        # -- Create ManagedCertificate resource and annotations for Google Load balancer\n        ## Ref: https://cloud.google.com/kubernetes-engine/docs/how-to/managed-certs\n        create: true\n        # -- Additional domains for ManagedCertificate resource\n        extraDomains: []\n          # - argocd.example.com\n\n  # Dedicated gRPC ingress for ingress controllers that supports only single backend protocol per Ingress resource\n  # Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-2-multiple-ingress-objects-and-hosts\n  ingressGrpc:\n    # -- Enable an ingress resource for the Argo CD server for dedicated [gRPC-ingress]\n    enabled: false\n    # -- Additional ingress annotations for dedicated [gRPC-ingress]\n    annotations: {}\n    # -- Additional ingress labels for dedicated [gRPC-ingress]\n    labels: {}\n    # -- Defines which ingress controller will implement the resource [gRPC-ingress]\n    ingressClassName: \"\"\n\n    # -- Argo CD server hostname for dedicated [gRPC-ingress]\n    # @default -- `\"\"` (defaults to grpc.`server.ingress.hostname`)\n    hostname: \"\"\n\n    # -- Argo CD server ingress path for dedicated [gRPC-ingress]\n    path: /\n\n    # -- Ingress path type for dedicated [gRPC-ingress]. One of `Exact`, `Prefix` or `ImplementationSpecific`\n    pathType: Prefix\n\n    # -- Enable TLS configuration for the hostname defined at `server.ingressGrpc.hostname`\n    ## TLS certificate will be retrieved from a TLS secret with name: `argocd-server-grpc-tls`\n    tls: false\n\n    # -- The list of additional hostnames to be covered by ingress record\n    # @default -- `[]` (See [values.yaml])\n    extraHosts: []\n      # - name: grpc.argocd.example.com\n      #   path: /\n\n    # -- Additional ingress paths for dedicated [gRPC-ingress]\n    # @default -- `[]` (See [values.yaml])\n    ## Note: Supports use of custom Helm templates\n    extraPaths: []\n      # - path: /*\n      #   pathType: Prefix\n      #   backend:\n      #     service:\n      #       name: ssl-redirect\n      #       port:\n      #         name: use-annotation\n\n    # -- Additional ingress rules\n    # @default -- `[]` (See [values.yaml])\n    ## Note: Supports use of custom Helm templates\n    extraRules: []\n      # - http:\n      #     paths:\n      #     - path: /\n      #       pathType: Prefix\n      #       backend:\n      #         service:\n      #           name: '{{ include \"argo-cd.server.fullname\" . }}'\n      #           port:\n      #             name: '{{ .Values.server.service.servicePortHttpName }}'\n\n    # -- Additional TLS configuration for dedicated [gRPC-ingress]\n    # @default -- `[]` (See [values.yaml])\n    extraTls: []\n      # - secretName: your-certificate-name\n      #   hosts:\n      #     - argocd.example.com\n\n  # Create a OpenShift Route with SSL passthrough for UI and CLI\n  # Consider setting 'hostname' e.g. https://argocd.apps-crc.testing/ using your Default Ingress Controller Domain\n  # Find your domain with: kubectl describe --namespace=openshift-ingress-operator ingresscontroller/default | grep Domain:\n  # If 'hostname' is an empty string \"\" OpenShift will create a hostname for you.\n  route:\n    # -- Enable an OpenShift Route for the Argo CD server\n    enabled: false\n    # -- Openshift Route annotations\n    annotations: {}\n    # -- Hostname of OpenShift Route\n    hostname: \"\"\n    # -- Termination type of Openshift Route\n    termination_type: passthrough\n    # -- Termination policy of Openshift Route\n    termination_policy: None\n\n  ## Enable this and set the rules: to whatever custom rules you want for the Cluster Role resource.\n  ## Defaults to off\n  clusterRoleRules:\n    # -- Enable custom rules for the server's ClusterRole resource\n    enabled: false\n    # -- List of custom rules for the server's ClusterRole resource\n    rules: []\n\n## Repo Server\nrepoServer:\n  # -- Repo server name\n  name: repo-server\n\n  # -- The number of repo server pods to run\n  replicas: 1\n\n  # -- Runtime class name for the repo server\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  ## Repo server Horizontal Pod Autoscaler\n  autoscaling:\n    # -- Enable Horizontal Pod Autoscaler ([HPA]) for the repo server\n    enabled: false\n    # -- Minimum number of replicas for the repo server [HPA]\n    minReplicas: 1\n    # -- Maximum number of replicas for the repo server [HPA]\n    maxReplicas: 5\n    # -- Average CPU utilization percentage for the repo server [HPA]\n    targetCPUUtilizationPercentage: 50\n    # -- Average memory utilization percentage for the repo server [HPA]\n    targetMemoryUtilizationPercentage: 50\n    # -- Configures the scaling behavior of the target in both Up and Down directions.\n    behavior: {}\n      # scaleDown:\n      #  stabilizationWindowSeconds: 300\n      #  policies:\n      #   - type: Pods\n      #     value: 1\n      #     periodSeconds: 180\n      # scaleUp:\n      #   stabilizationWindowSeconds: 300\n      #   policies:\n      #   - type: Pods\n      #     value: 2\n      #     periodSeconds: 60\n    # -- Configures custom HPA metrics for the Argo CD repo server\n    # Ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/\n    metrics: []\n\n  ## Repo server Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the repo server\n    enabled: false\n    # -- Labels to be added to repo server pdb\n    labels: {}\n    # -- Annotations to be added to repo server pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailable after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `repoServer.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## Repo server image\n  image:\n    # -- Repository to use for the repo server\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the repo server\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the repo server\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- Additional command line arguments to pass to repo server\n  extraArgs: []\n\n  # -- Environment variables to pass to repo server\n  env: []\n\n  # -- envFrom to pass to repo server\n  # @default -- `[]` (See [values.yaml])\n  envFrom: []\n  # - configMapRef:\n  #     name: config-map-name\n  # - secretRef:\n  #     name: secret-name\n\n  # -- Specify postStart and preStop lifecycle hooks for your argo-repo-server container\n  lifecycle: {}\n\n  # -- Additional containers to be added to the repo server pod\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/user-guide/config-management-plugins/\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n    # - name: cmp-my-plugin\n    #   command:\n    #     - \"/var/run/argocd/argocd-cmp-server\"\n    #   image: busybox\n    #   securityContext:\n    #     runAsNonRoot: true\n    #     runAsUser: 999\n    #   volumeMounts:\n    #     - mountPath: /var/run/argocd\n    #       name: var-files\n    #     - mountPath: /home/argocd/cmp-server/plugins\n    #       name: plugins\n    #     # Remove this volumeMount if you've chosen to bake the config file into the sidecar image.\n    #     - mountPath: /home/argocd/cmp-server/config/plugin.yaml\n    #       subPath: my-plugin.yaml\n    #       name: argocd-cmp-cm\n    #     # Starting with v2.4, do NOT mount the same tmp volume as the repo-server container. The filesystem separation helps\n    #     # mitigate path traversal attacks.\n    #     - mountPath: /tmp\n    #       name: cmp-tmp\n    # - name: cmp-my-plugin2\n    #   command:\n    #     - \"/var/run/argocd/argocd-cmp-server\"\n    #   image: busybox\n    #   securityContext:\n    #     runAsNonRoot: true\n    #     runAsUser: 999\n    #   volumeMounts:\n    #     - mountPath: /var/run/argocd\n    #       name: var-files\n    #     # Remove this volumeMount if you've chosen to bake the config file into the sidecar image.\n    #     - mountPath: /home/argocd/cmp-server/plugins\n    #       name: plugins\n    #     - mountPath: /home/argocd/cmp-server/config/plugin.yaml\n    #       subPath: my-plugin2.yaml\n    #       name: argocd-cmp-cm\n    #     # Starting with v2.4, do NOT mount the same tmp volume as the repo-server container. The filesystem separation helps\n    #     # mitigate path traversal attacks.\n    #     - mountPath: /tmp\n    #       name: cmp-tmp\n\n  # -- Init containers to add to the repo server pods\n  initContainers: []\n\n  # -- Additional volumeMounts to the repo server main container\n  volumeMounts: []\n\n  # -- Additional volumes to the repo server pod\n  volumes: []\n  #  - name: argocd-cmp-cm\n  #    configMap:\n  #      name: argocd-cmp-cm\n  #  - name: cmp-tmp\n  #    emptyDir: {}\n\n  # -- Volumes to be used in replacement of emptydir on default volumes\n  existingVolumes: {}\n  #  gpgKeyring:\n  #    persistentVolumeClaim:\n  #      claimName: pvc-argocd-repo-server-keyring\n  #  helmWorkingDir:\n  #    persistentVolumeClaim:\n  #      claimName: pvc-argocd-repo-server-workdir\n  #  tmp:\n  #    persistentVolumeClaim:\n  #      claimName: pvc-argocd-repo-server-tmp\n  #  varFiles:\n  #    persistentVolumeClaim:\n  #      claimName: pvc-argocd-repo-server-varfiles\n  #  plugins:\n  #    persistentVolumeClaim:\n  #      claimName: pvc-argocd-repo-server-plugins\n\n  ## RepoServer emptyDir volumes\n  emptyDir:\n    # -- EmptyDir size limit for repo server\n    # @default -- `\"\"` (defaults not set if not specified i.e. no size limit)\n    sizeLimit: \"\"\n    # sizeLimit: \"1Gi\"\n\n  # -- Toggle the usage of a ephemeral Helm working directory\n  useEphemeralHelmWorkingDir: true\n\n  # -- Annotations to be added to repo server Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations to be added to repo server pods\n  podAnnotations: {}\n\n  # -- Labels to be added to repo server pods\n  podLabels: {}\n\n  # -- Resource limits and requests for the repo server pods\n  resources: {}\n  #  limits:\n  #    cpu: 50m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 10m\n  #    memory: 64Mi\n\n  # Repo server container ports\n  containerPorts:\n    # -- Repo server container port\n    server: 8081\n    # -- Metrics container port\n    metrics: 8084\n\n  # -- Host Network for Repo server pods\n  hostNetwork: false\n\n    # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for Repo server pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- Repo server container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    seccompProfile:\n      type: RuntimeDefault\n    capabilities:\n      drop:\n      - ALL\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  livenessProbe:\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules to the deployment\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the repo server\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy to be added to the repo server Deployment\n  deploymentStrategy: {}\n    # type: RollingUpdate\n    # rollingUpdate:\n    #   maxSurge: 25%\n    #   maxUnavailable: 25%\n\n  # -- Priority class for the repo server pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # TLS certificate configuration via Secret\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/tls/#configuring-tls-to-argocd-repo-server\n  ## Note: Issuing certificates via cert-manager in not supported right now because it's not possible to restart repo server automatically without extra controllers.\n  certificateSecret:\n    # -- Create argocd-repo-server-tls secret\n    enabled: false\n    # -- Annotations to be added to argocd-repo-server-tls secret\n    annotations: {}\n    # -- Labels to be added to argocd-repo-server-tls secret\n    labels: {}\n    # -- Certificate authority. Required for self-signed certificates.\n    ca: ''\n    # -- Certificate private key\n    key: ''\n    # -- Certificate data. Must contain SANs of Repo service (ie: argocd-repo-server, argocd-repo-server.argo-cd.svc)\n    crt: ''\n\n  ## Repo server service configuration\n  service:\n    # -- Repo server service annotations\n    annotations: {}\n    # -- Repo server service labels\n    labels: {}\n    # -- Repo server service port\n    port: 8081\n    # -- Repo server service port name\n    portName: tcp-repo-server\n\n  ## Repo server metrics service configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: \"\"\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8084\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus ServiceMonitor scrapeTimeout. If empty, Prometheus uses the global scrape timeout unless it is less than the target's scrape interval value in which the latter is used.\n      scrapeTimeout: \"\"\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\" # \"monitoring\"\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n\n  ## Enable Custom Rules for the Repo server's Cluster Role resource\n  ## Enable this and set the rules: to whatever custom rules you want for the Cluster Role resource.\n  ## Defaults to off\n  clusterRoleRules:\n    # -- Enable custom rules for the Repo server's Cluster Role resource\n    enabled: false\n    # -- List of custom rules for the Repo server's Cluster Role resource\n    rules: []\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  ## Repo server service account\n  ## If create is set to true, make sure to uncomment the name and update the rbac section below\n  serviceAccount:\n    # -- Create repo server service account\n    create: true\n    # -- Repo server service account name\n    name: \"\" # \"argocd-repo-server\"\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Labels applied to created service account\n    labels: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Repo server rbac rules\n  rbac: []\n  #   - apiGroups:\n  #     - argoproj.io\n  #     resources:\n  #     - applications\n  #     verbs:\n  #     - get\n  #     - list\n  #     - watch\n\n## ApplicationSet controller\napplicationSet:\n  # -- ApplicationSet controller name string\n  name: applicationset-controller\n\n  # -- The number of ApplicationSet controller pods to run\n  replicas: 1\n\n  # -- Runtime class name for the ApplicationSet controller\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  ## ApplicationSet controller Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the ApplicationSet controller\n    enabled: false\n    # -- Labels to be added to ApplicationSet controller pdb\n    labels: {}\n    # -- Annotations to be added to ApplicationSet controller pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailable after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `applicationSet.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## ApplicationSet controller image\n  image:\n    # -- Repository to use for the ApplicationSet controller\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the ApplicationSet controller\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the ApplicationSet controller\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- If defined, uses a Secret to pull an image from a private Docker registry or repository.\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- ApplicationSet controller command line flags\n  extraArgs: []\n\n  # -- Environment variables to pass to the ApplicationSet controller\n  extraEnv: []\n    # - name: \"MY_VAR\"\n    #   value: \"value\"\n\n  # -- envFrom to pass to the ApplicationSet controller\n  # @default -- `[]` (See [values.yaml])\n  extraEnvFrom: []\n    # - configMapRef:\n    #     name: config-map-name\n    # - secretRef:\n    #     name: secret-name\n\n  # -- Additional containers to be added to the ApplicationSet controller pod\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n\n  # -- Init containers to add to the ApplicationSet controller pod\n  ## Note: Supports use of custom Helm templates\n  initContainers: []\n\n  # -- List of extra mounts to add (normally used with extraVolumes)\n  extraVolumeMounts: []\n\n  # -- List of extra volumes to add\n  extraVolumes: []\n\n  ## ApplicationSet controller emptyDir volumes\n  emptyDir:\n    # -- EmptyDir size limit for applicationSet controller\n    # @default -- `\"\"` (defaults not set if not specified i.e. no size limit)\n    sizeLimit: \"\"\n    # sizeLimit: \"1Gi\"\n\n  ## Metrics service configuration\n  metrics:\n    # -- Deploy metrics service\n    enabled: false\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: \"\"\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8080\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor interval\n      interval: 30s\n      # -- Prometheus ServiceMonitor scrapeTimeout. If empty, Prometheus uses the global scrape timeout unless it is less than the target's scrape interval value in which the latter is used.\n      scrapeTimeout: \"\"\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- Prometheus ServiceMonitor namespace\n      namespace: \"\"  # monitoring\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n\n  ## ApplicationSet service configuration\n  service:\n    # -- ApplicationSet service annotations\n    annotations: {}\n    # -- ApplicationSet service labels\n    labels: {}\n    # -- ApplicationSet service type\n    type: ClusterIP\n    # -- ApplicationSet service port\n    port: 7000\n    # -- ApplicationSet service port name\n    portName: http-webhook\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  serviceAccount:\n    # -- Create ApplicationSet controller service account\n    create: true\n    # -- ApplicationSet controller service account name\n    name: argocd-applicationset-controller\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Labels applied to created service account\n    labels: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Annotations to be added to ApplicationSet controller Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations for the ApplicationSet controller pods\n  podAnnotations: {}\n\n  # -- Labels for the ApplicationSet controller pods\n  podLabels: {}\n\n  # -- Resource limits and requests for the ApplicationSet controller pods.\n  resources: {}\n    # limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\n  # ApplicationSet controller container ports\n  containerPorts:\n    # -- Metrics container port\n    metrics: 8080\n    # -- Probe container port\n    probe: 8081\n    # -- Webhook container port\n    webhook: 7000\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for ApplicationSet controller pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- ApplicationSet controller container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    seccompProfile:\n      type: RuntimeDefault\n    capabilities:\n      drop:\n      - ALL\n\n  ## Probes for ApplicationSet controller (optional)\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Enable Kubernetes liveness probe for ApplicationSet controller\n    enabled: false\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n\n  livenessProbe:\n    # -- Enable Kubernetes liveness probe for ApplicationSet controller\n    enabled: false\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the ApplicationSet controller\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy to be added to the ApplicationSet controller Deployment\n  deploymentStrategy: {}\n    # type: RollingUpdate\n    # rollingUpdate:\n    #   maxSurge: 25%\n    #   maxUnavailable: 25%\n\n  # -- Priority class for the ApplicationSet controller pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # TLS certificate configuration via cert-manager\n  ## Ref: https://argo-cd.readthedocs.io/en/stable/operator-manual/tls/#tls-configuration\n  certificate:\n    # -- Deploy a Certificate resource (requires cert-manager)\n    enabled: false\n    # -- Certificate primary domain (commonName)\n    # @default -- `\"\"` (defaults to global.domain)\n    domain: \"\"\n    # -- Certificate Subject Alternate Names (SANs)\n    additionalHosts: []\n    # -- The requested 'duration' (i.e. lifetime) of the certificate.\n    # @default -- `\"\"` (defaults to 2160h = 90d if not specified)\n    ## Ref: https://cert-manager.io/docs/usage/certificate/#renewal\n    duration: \"\"\n    # -- How long before the expiry a certificate should be renewed.\n    # @default -- `\"\"` (defaults to 360h = 15d if not specified)\n    ## Ref: https://cert-manager.io/docs/usage/certificate/#renewal\n    renewBefore: \"\"\n    # Certificate issuer\n    ## Ref: https://cert-manager.io/docs/concepts/issuer\n    issuer:\n      # -- Certificate issuer group. Set if using an external issuer. Eg. `cert-manager.io`\n      group: \"\"\n      # -- Certificate issuer kind. Either `Issuer` or `ClusterIssuer`\n      kind: \"\"\n      # -- Certificate issuer name. Eg. `letsencrypt`\n      name: \"\"\n    # Private key of the certificate\n    privateKey:\n      # -- Rotation policy of private key when certificate is re-issued. Either: `Never` or `Always`\n      rotationPolicy: Never\n      # -- The private key cryptography standards (PKCS) encoding for private key. Either: `PCKS1` or `PKCS8`\n      encoding: PKCS1\n      # -- Algorithm used to generate certificate private key. One of: `RSA`, `Ed25519` or `ECDSA`\n      algorithm: RSA\n      # -- Key bit size of the private key. If algorithm is set to `Ed25519`, size is ignored.\n      size: 2048\n    # -- Annotations to be applied to the ApplicationSet Certificate\n    annotations: {}\n\n  ## Ingress for the Git Generator webhook\n  ## Ref: https://argocd-applicationset.readthedocs.io/en/master/Generators-Git/#webhook-configuration)\n  ingress:\n    # -- Enable an ingress resource for ApplicationSet webhook\n    enabled: false\n    # -- Additional ingress labels\n    labels: {}\n    # -- Additional ingress annotations\n    annotations: {}\n\n    # -- Defines which ingress ApplicationSet controller will implement the resource\n    ingressClassName: \"\"\n\n    # -- Argo CD ApplicationSet hostname\n    # @default -- `\"\"` (defaults to global.domain)\n    hostname: \"\"\n\n    # -- List of ingress paths\n    path: /api/webhook\n\n    # -- Ingress path type. One of `Exact`, `Prefix` or `ImplementationSpecific`\n    pathType: Prefix\n\n    # -- Enable TLS configuration for the hostname defined at `applicationSet.webhook.ingress.hostname`\n    ## TLS certificate will be retrieved from a TLS secret with name:`argocd-applicationset-controller-tls`\n    tls: false\n\n    # -- The list of additional hostnames to be covered by ingress record\n    # @default -- `[]` (See [values.yaml])\n    extraHosts: []\n      # - name: argocd.example.com\n      #   path: /\n\n    # -- Additional ingress paths\n    # @default -- `[]` (See [values.yaml])\n    extraPaths: []\n      # - path: /*\n      #   pathType: Prefix\n      #   backend:\n      #     service:\n      #       name: ssl-redirect\n      #       port:\n      #         name: use-annotation\n\n    # -- Additional ingress rules\n    # @default -- `[]` (See [values.yaml])\n    ## Note: Supports use of custom Helm templates\n    extraRules: []\n      # - http:\n      #    paths:\n      #    - path: /api/webhook\n      #      pathType: Prefix\n      #      backend:\n      #        service:\n      #          name: '{{ include \"argo-cd.applicationSet.fullname\" . }}'\n      #          port:\n      #            name: '{{ .Values.applicationSet.service.portName }}'\n\n    # -- Additional ingress TLS configuration\n    # @default -- `[]` (See [values.yaml])\n    extraTls: []\n      # - secretName: argocd-applicationset-tls\n      #   hosts:\n      #     - argocd-applicationset.example.com\n  # -- Enable ApplicationSet in any namespace feature\n  allowAnyNamespace: false\n## Notifications controller\nnotifications:\n  # -- Enable notifications controller\n  enabled: true\n\n  # -- Notifications controller name string\n  name: notifications-controller\n\n  # -- Argo CD dashboard url; used in place of {{.context.argocdUrl}} in templates\n  # @default -- `\"\"` (defaults to https://`global.domain`)\n  argocdUrl: \"\"\n\n  # -- Runtime class name for the notifications controller\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  ## Notifications controller Pod Disruption Budget\n  ## Ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  pdb:\n    # -- Deploy a [PodDisruptionBudget] for the notifications controller\n    enabled: false\n    # -- Labels to be added to notifications controller pdb\n    labels: {}\n    # -- Annotations to be added to notifications controller pdb\n    annotations: {}\n    # -- Number of pods that are available after eviction as number or percentage (eg.: 50%)\n    # @default -- `\"\"` (defaults to 0 if not specified)\n    minAvailable: \"\"\n    # -- Number of pods that are unavailable after eviction as number or percentage (eg.: 50%).\n    ## Has higher precedence over `notifications.pdb.minAvailable`\n    maxUnavailable: \"\"\n\n  ## Notifications controller image\n  image:\n    # -- Repository to use for the notifications controller\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the notifications controller\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the notifications controller\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- Secrets with credentials to pull images from a private registry\n  # @default -- `[]` (defaults to global.imagePullSecrets)\n  imagePullSecrets: []\n\n  # -- Notifications controller log format. Either `text` or `json`\n  # @default -- `\"\"` (defaults to global.logging.format)\n  logFormat: \"\"\n  # -- Notifications controller log level. One of: `debug`, `info`, `warn`, `error`\n  # @default -- `\"\"` (defaults to global.logging.level)\n  logLevel: \"\"\n\n  # -- Extra arguments to provide to the notifications controller\n  extraArgs: []\n\n  # -- Additional container environment variables\n  extraEnv: []\n\n  # -- envFrom to pass to the notifications controller\n  # @default -- `[]` (See [values.yaml])\n  extraEnvFrom: []\n    # - configMapRef:\n    #     name: config-map-name\n    # - secretRef:\n    #     name: secret-name\n\n  # -- Additional containers to be added to the notifications controller pod\n  ## Note: Supports use of custom Helm templates\n  extraContainers: []\n\n  # -- Init containers to add to the notifications controller pod\n  ## Note: Supports use of custom Helm templates\n  initContainers: []\n\n  # -- List of extra mounts to add (normally used with extraVolumes)\n  extraVolumeMounts: []\n\n  # -- List of extra volumes to add\n  extraVolumes: []\n\n  # -- Define user-defined context\n  ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/templates/#defining-user-defined-context\n  context: {}\n    # region: east\n    # environmentName: staging\n\n  secret:\n    # -- Whether helm chart creates notifications controller secret\n    ## If true, will create a secret with the name below. Otherwise, will assume existence of a secret with that name.\n    create: true\n\n    # -- notifications controller Secret name\n    name: \"argocd-notifications-secret\"\n\n    # -- key:value pairs of annotations to be added to the secret\n    annotations: {}\n\n    # -- key:value pairs of labels to be added to the secret\n    labels: {}\n\n    # -- Generic key:value pairs to be inserted into the secret\n    ## Can be used for templates, notification services etc. Some examples given below.\n    ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/services/overview/\n    items: {}\n      # slack-token:\n      #   # For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/services/slack/\n\n      # grafana-apiKey:\n      #   # For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/services/grafana/\n\n      # webhooks-github-token:\n\n      # email-username:\n      # email-password:\n        # For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/services/email/\n\n  metrics:\n    # -- Enables prometheus metrics server\n    enabled: false\n    # -- Metrics port\n    port: 9001\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: \"\"\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port name\n      portName: http-metrics\n    serviceMonitor:\n      # -- Enable a prometheus ServiceMonitor\n      enabled: false\n      # -- Prometheus ServiceMonitor selector\n      selector: {}\n        # prometheus: kube-prometheus\n      # -- Prometheus ServiceMonitor labels\n      additionalLabels: {}\n      # -- Prometheus ServiceMonitor annotations\n      annotations: {}\n      # namespace: monitoring\n      # interval: 30s\n      # scrapeTimeout: 10s\n      # -- Prometheus ServiceMonitor scheme\n      scheme: \"\"\n      # -- Prometheus ServiceMonitor tlsConfig\n      tlsConfig: {}\n      # -- When true, honorLabels preserves the metric’s labels when they collide with the target’s labels.\n      honorLabels: false\n      # -- Prometheus [RelabelConfigs] to apply to samples before scraping\n      relabelings: []\n      # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion\n      metricRelabelings: []\n\n  # -- Configures notification services such as slack, email or custom webhook\n  # @default -- See [values.yaml]\n  ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/services/overview/\n  notifiers: {}\n    # service.slack: |\n    #   token: $slack-token\n\n  # -- Annotations to be applied to the notifications controller Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations to be applied to the notifications controller Pods\n  podAnnotations: {}\n\n  # -- Labels to be applied to the notifications controller Pods\n  podLabels: {}\n\n  # -- Resource limits and requests for the notifications controller\n  resources: {}\n    # limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\n  # Notification controller container ports\n  containerPorts:\n    # -- Metrics container port\n    metrics: 9001\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for notifications controller Pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- Notification controller container-level security Context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    seccompProfile:\n      type: RuntimeDefault\n    capabilities:\n      drop:\n      - ALL\n\n  ## Probes for notifications controller Pods (optional)\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Enable Kubernetes liveness probe for notifications controller Pods\n    enabled: false\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n\n  livenessProbe:\n    # -- Enable Kubernetes liveness probe for notifications controller Pods\n    enabled: false\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 10\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n    # -- Minimum consecutive successes for the [probe] to be considered successful after having failed\n    successThreshold: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the application controller\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy to be added to the notifications controller Deployment\n  deploymentStrategy:\n    type: Recreate\n\n  # -- Priority class for the notifications controller pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\"\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: true\n\n  serviceAccount:\n    # -- Create notifications controller service account\n    create: true\n    # -- Notification controller service account name\n    name: argocd-notifications-controller\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Labels applied to created service account\n    labels: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  cm:\n    # -- Whether helm chart creates notifications controller config map\n    create: true\n\n  ## Enable this and set the rules: to whatever custom rules you want for the Cluster Role resource.\n  ## Defaults to off\n  clusterRoleRules:\n    # -- List of custom rules for the notifications controller's ClusterRole resource\n    rules: []\n\n  # -- Contains centrally managed global application subscriptions\n  ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/subscriptions/\n  subscriptions: []\n    # # subscription for on-sync-status-unknown trigger notifications\n    # - recipients:\n    #   - slack:test2\n    #   - email:test@gmail.com\n    #   triggers:\n    #   - on-sync-status-unknown\n    # # subscription restricted to applications with matching labels only\n    # - recipients:\n    #   - slack:test3\n    #   selector: test=true\n    #   triggers:\n    #   - on-sync-status-unknown\n\n  # -- The notification template is used to generate the notification content\n  ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/templates/\n  templates: {}\n    # template.app-deployed: |\n    #   email:\n    #     subject: New version of an application {{.app.metadata.name}} is up and running.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:white_check_mark:{{end}} Application {{.app.metadata.name}} is now running new version of deployments manifests.\n    #   slack:\n    #     attachments: |\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#18be52\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Revision\",\n    #           \"value\": \"{{.app.status.sync.revision}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-health-degraded: |\n    #   email:\n    #     subject: Application {{.app.metadata.name}} has degraded.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:exclamation:{{end}} Application {{.app.metadata.name}} has degraded.\n    #     Application details: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}.\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\": \"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#f4c030\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-failed: |\n    #   email:\n    #     subject: Failed to sync application {{.app.metadata.name}}.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:exclamation:{{end}}  The sync operation of application {{.app.metadata.name}} has failed at {{.app.status.operationState.finishedAt}} with the following error: {{.app.status.operationState.message}}\n    #     Sync operation details are available at: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}?operation=true .\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#E96D76\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-running: |\n    #   email:\n    #     subject: Start syncing application {{.app.metadata.name}}.\n    #   message: |\n    #     The sync operation of application {{.app.metadata.name}} has started at {{.app.status.operationState.startedAt}}.\n    #     Sync operation details are available at: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}?operation=true .\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#0DADEA\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-status-unknown: |\n    #   email:\n    #     subject: Application {{.app.metadata.name}} sync status is 'Unknown'\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:exclamation:{{end}} Application {{.app.metadata.name}} sync is 'Unknown'.\n    #     Application details: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}.\n    #     {{if ne .serviceType \"slack\"}}\n    #     {{range $c := .app.status.conditions}}\n    #         * {{$c.message}}\n    #     {{end}}\n    #     {{end}}\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#E96D76\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n    # template.app-sync-succeeded: |\n    #   email:\n    #     subject: Application {{.app.metadata.name}} has been successfully synced.\n    #   message: |\n    #     {{if eq .serviceType \"slack\"}}:white_check_mark:{{end}} Application {{.app.metadata.name}} has been successfully synced at {{.app.status.operationState.finishedAt}}.\n    #     Sync operation details are available at: {{.context.argocdUrl}}/applications/{{.app.metadata.name}}?operation=true .\n    #   slack:\n    #     attachments: |-\n    #       [{\n    #         \"title\": \"{{ .app.metadata.name}}\",\n    #         \"title_link\":\"{{.context.argocdUrl}}/applications/{{.app.metadata.name}}\",\n    #         \"color\": \"#18be52\",\n    #         \"fields\": [\n    #         {\n    #           \"title\": \"Sync Status\",\n    #           \"value\": \"{{.app.status.sync.status}}\",\n    #           \"short\": true\n    #         },\n    #         {\n    #           \"title\": \"Repository\",\n    #           \"value\": \"{{.app.spec.source.repoURL}}\",\n    #           \"short\": true\n    #         }\n    #         {{range $index, $c := .app.status.conditions}}\n    #         {{if not $index}},{{end}}\n    #         {{if $index}},{{end}}\n    #         {\n    #           \"title\": \"{{$c.type}}\",\n    #           \"value\": \"{{$c.message}}\",\n    #           \"short\": true\n    #         }\n    #         {{end}}\n    #         ]\n    #       }]\n\n  # -- The trigger defines the condition when the notification should be sent\n  ## For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/triggers/\n  triggers: {}\n    # trigger.on-deployed: |\n    #   - description: Application is synced and healthy. Triggered once per commit.\n    #     oncePer: app.status.sync.revision\n    #     send:\n    #     - app-deployed\n    #     when: app.status.operationState.phase in ['Succeeded'] and app.status.health.status == 'Healthy'\n    # trigger.on-health-degraded: |\n    #   - description: Application has degraded\n    #     send:\n    #     - app-health-degraded\n    #     when: app.status.health.status == 'Degraded'\n    # trigger.on-sync-failed: |\n    #   - description: Application syncing has failed\n    #     send:\n    #     - app-sync-failed\n    #     when: app.status.operationState.phase in ['Error', 'Failed']\n    # trigger.on-sync-running: |\n    #   - description: Application is being synced\n    #     send:\n    #     - app-sync-running\n    #     when: app.status.operationState.phase in ['Running']\n    # trigger.on-sync-status-unknown: |\n    #   - description: Application status is 'Unknown'\n    #     send:\n    #     - app-sync-status-unknown\n    #     when: app.status.sync.status == 'Unknown'\n    # trigger.on-sync-succeeded: |\n    #   - description: Application syncing has succeeded\n    #     send:\n    #     - app-sync-succeeded\n    #     when: app.status.operationState.phase in ['Succeeded']\n    #\n    # For more information: https://argo-cd.readthedocs.io/en/stable/operator-manual/notifications/triggers/#default-triggers\n    # defaultTriggers: |\n    #   - on-sync-status-unknown\n\ncommitServer:\n  # -- Enable commit server\n  enabled: false\n\n  # -- Commit server name\n  name: commit-server\n\n  # -- Runtime class name for the commit server\n  # @default -- `\"\"` (defaults to global.runtimeClassName)\n  runtimeClassName: \"\"\n\n  ## commit server controller image\n  image:\n    # -- Repository to use for the commit server\n    # @default -- `\"\"` (defaults to global.image.repository)\n    repository: \"\"\n    # -- Tag to use for the commit server\n    # @default -- `\"\"` (defaults to global.image.tag)\n    tag: \"\"\n    # -- Image pull policy for the commit server\n    # @default -- `\"\"` (defaults to global.image.imagePullPolicy)\n    imagePullPolicy: \"\"\n\n  # -- commit server command line flags\n  extraArgs: []\n\n  # -- Environment variables to pass to the commit server\n  extraEnv: []\n    # - name: \"MY_VAR\"\n    #   value: \"value\"\n\n  # -- envFrom to pass to the commit server\n  # @default -- `[]` (See [values.yaml])\n  extraEnvFrom: []\n    # - configMapRef:\n    #     name: config-map-name\n    # - secretRef:\n    #     name: secret-name\n\n  # -- List of extra mounts to add (normally used with extraVolumes)\n  extraVolumeMounts: []\n\n  # -- List of extra volumes to add\n  extraVolumes: []\n\n  metrics:\n    # -- Enables prometheus metrics server\n    enabled: false\n    service:\n      # -- Metrics service type\n      type: ClusterIP\n      # -- Metrics service clusterIP. `None` makes a \"headless service\" (no virtual IP)\n      clusterIP: \"\"\n      # -- Metrics service annotations\n      annotations: {}\n      # -- Metrics service labels\n      labels: {}\n      # -- Metrics service port\n      servicePort: 8087\n      # -- Metrics service port name\n      portName: metrics\n\n  ## commit server service configuration\n  service:\n    # -- commit server service annotations\n    annotations: {}\n    # -- commit server service labels\n    labels: {}\n\n  # -- Automount API credentials for the Service Account into the pod.\n  automountServiceAccountToken: false\n\n  serviceAccount:\n    # -- Create commit server service account\n    create: true\n    # -- commit server service account name\n    name: argocd-commit-server\n    # -- Annotations applied to created service account\n    annotations: {}\n    # -- Labels applied to created service account\n    labels: {}\n    # -- Automount API credentials for the Service Account\n    automountServiceAccountToken: true\n\n  # -- Annotations to be added to commit server Deployment\n  deploymentAnnotations: {}\n\n  # -- Annotations for the commit server pods\n  podAnnotations: {}\n\n  # -- Labels for the commit server pods\n  podLabels: {}\n\n  # -- Resource limits and requests for the commit server pods.\n  resources: {}\n    # limits:\n    #   cpu: 100m\n    #   memory: 128Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 128Mi\n\n  # -- [DNS configuration]\n  dnsConfig: {}\n  # -- Alternative DNS policy for commit server pods\n  dnsPolicy: \"ClusterFirst\"\n\n  # -- commit server container-level security context\n  # @default -- See [values.yaml]\n  containerSecurityContext:\n    runAsNonRoot: true\n    readOnlyRootFilesystem: true\n    allowPrivilegeEscalation: false\n    capabilities:\n      drop:\n      - ALL\n    seccompProfile:\n      type: RuntimeDefault\n\n  ## Probes for commit server (optional)\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  readinessProbe:\n    # -- Enable Kubernetes liveness probe for commit server\n    enabled: true\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 5\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 10\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 1\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n\n  livenessProbe:\n    # -- Enable Kubernetes liveness probe for commit server\n    enabled: true\n    # -- Number of seconds after the container has started before [probe] is initiated\n    initialDelaySeconds: 30\n    # -- How often (in seconds) to perform the [probe]\n    periodSeconds: 30\n    # -- Number of seconds after which the [probe] times out\n    timeoutSeconds: 5\n    # -- Minimum consecutive failures for the [probe] to be considered failed after having succeeded\n    failureThreshold: 3\n\n  # -- terminationGracePeriodSeconds for container lifecycle hook\n  terminationGracePeriodSeconds: 30\n\n  # -- [Node selector]\n  # @default -- `{}` (defaults to global.nodeSelector)\n  nodeSelector: {}\n\n  # -- [Tolerations] for use with node taints\n  # @default -- `[]` (defaults to global.tolerations)\n  tolerations: []\n\n  # -- Assign custom [affinity] rules\n  # @default -- `{}` (defaults to global.affinity preset)\n  affinity: {}\n\n  # -- Assign custom [TopologySpreadConstraints] rules to the commit server\n  # @default -- `[]` (defaults to global.topologySpreadConstraints)\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n  ## If labelSelector is left out, it will default to the labelSelector configuration of the deployment\n  topologySpreadConstraints: []\n    # - maxSkew: 1\n    #   topologyKey: topology.kubernetes.io/zone\n    #   whenUnsatisfiable: DoNotSchedule\n\n  # -- Deployment strategy to be added to the commit server Deployment\n  deploymentStrategy: {}\n    # type: RollingUpdate\n    # rollingUpdate:\n    #   maxSurge: 25%\n    #   maxUnavailable: 25%\n\n  # -- Priority class for the commit server pods\n  # @default -- `\"\"` (defaults to global.priorityClassName)\n  priorityClassName: \"\""
            ],
            "verify": false,
            "version": "7.7.5",
            "wait": true,
            "wait_for_jobs": false
          },
          "sensitive_attributes": [],
          "private": "eyJzY2hlbWFfdmVyc2lvbiI6IjEifQ==",
          "dependencies": [
            "kind_cluster.default"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kind_cluster",
      "name": "default",
      "provider": "provider[\"registry.terraform.io/lukekalbfleisch/kind\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "client_certificate": "-----BEGIN CERTIFICATE-----\nMIIDKTCCAhGgAwIBAgIIFr05xlKNza0wDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yNTAyMjQxMDM3MThaFw0yNjAyMjQxMDQyMTlaMDwx\nHzAdBgNVBAoTFmt1YmVhZG06Y2x1c3Rlci1hZG1pbnMxGTAXBgNVBAMTEGt1YmVy\nbmV0ZXMtYWRtaW4wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDHPSnF\nqcbxnVfqwgbsyi5naAM/tnS4hWkKeGNfhTVgffOkgWuS6V2Qe/XvUS5WrKXQVqpG\nOhic8nzt6fN4eZFeOUCcgEmQSDSXDLkG5f5O/aNSjYFVNqIi5qNvEHmUzV6Nhf0C\nNdOBacm5Lq7DooOPs5EKBHsy0DHBdUyaFa8oNlOKEOTp/zPaa0MWFCHigMZMqYIg\nDhRC9mUwnQwWOC50oOX0HQCNJIPN01C7IqUGzWeKs7nUky7HnCmDsVfw0yGyQXrW\nARNM1LHq1x9bgs1Su2UrCAQAyhaKXYKOVVWjc7b+HGDrfhEQVuA6SVlfhbDJ8Ux/\nQyMfCDyOSvF25M1/AgMBAAGjVjBUMA4GA1UdDwEB/wQEAwIFoDATBgNVHSUEDDAK\nBggrBgEFBQcDAjAMBgNVHRMBAf8EAjAAMB8GA1UdIwQYMBaAFDv0zlGd+JhfkB7r\nUja9ML41iJ1dMA0GCSqGSIb3DQEBCwUAA4IBAQAvd9ao/jwFAlJl74eMHUVqW6I7\n2d04AZhKuV70xBd/RhUYghE06NMzfW41ag41xkw4BdsP7cHv46YMCdJSmzmF2G0r\nLMKBeJ8SxlXKS63wg+0dMqWE/1PVcMHin82lOsTuLv8fpH+TnaE/ospqM3TvkcHn\nrw4wvgQdkubbsQLxuUZSgluIJMdH8fv8Wga4cYvozBQRTJ2HvwHVpaAcQ5mUKMGJ\nRTNWjUEhOUNrVcF6AeltfEkq1JHK5+11w+uGeQOsrB2ker2OeyCOBW9kJ9hec8Ru\nwc5t9DtTf9taAEtIs5yLOuQDZjrZQqRKhvjNnvH5rIHB/RbTLpE5eyTYG9m6\n-----END CERTIFICATE-----\n",
            "client_key": "-----BEGIN RSA PRIVATE KEY-----\nMIIEogIBAAKCAQEAxz0pxanG8Z1X6sIG7MouZ2gDP7Z0uIVpCnhjX4U1YH3zpIFr\nkuldkHv171EuVqyl0FaqRjoYnPJ87enzeHmRXjlAnIBJkEg0lwy5BuX+Tv2jUo2B\nVTaiIuajbxB5lM1ejYX9AjXTgWnJuS6uw6KDj7ORCgR7MtAxwXVMmhWvKDZTihDk\n6f8z2mtDFhQh4oDGTKmCIA4UQvZlMJ0MFjgudKDl9B0AjSSDzdNQuyKlBs1nirO5\n1JMux5wpg7FX8NMhskF61gETTNSx6tcfW4LNUrtlKwgEAMoWil2CjlVVo3O2/hxg\n634REFbgOklZX4WwyfFMf0MjHwg8jkrxduTNfwIDAQABAoIBABpcVk2HxAGtvrcZ\nys7DhVY7JcrlOhY72IUBHqzBtCk7IORQF0qNw8pdDFIInKftGdcx0D+QajdBwhO8\nU3FKLFiaHJlYQ+NqGkMt9MEb5wTOfDBs9oKuws75UwBb3qo4bd0tsCb9tik2NPFi\nYs8RjnSR3ovDwgUcFKky+tqcKduY8Jzhu/I684X64HHkL98klr+HKat//RXRqJMK\ncypLNOxqPogYpHi82InTCfMy3zxSQlMw0vcuQkWLsNeSdb0IzcGlej6JAIXqcu6a\nPtmDQKXQAIEyNr6bQb2L9oavBnK/pKS36ALTBIu5y7ZLHWFMkhQvowFXLAjYKZtd\nO3Ec+dECgYEA8JgWFF1+gPq/wf0c8Mg97QZDl+vQDxee45QWfmAFL9/o2WAap2py\nBwETnR9JXvEb2oia/KJpf/A8FtogxLbglY+/jH2t4TvbL/rRm3eZDCu9iYZ6agZO\nQURr8fddaqjjcru7l9Pat/2INsXn2jHN+fTHuftGS+HBF7uCQG/0JQkCgYEA0/8q\npersLBmc91E4F4Z7PgGj2Yh7xDkMYupojSiIk8Z9rq7IMwJcASJ/hhODdw8QzgGP\nkTwqK+jTLKKtQ1IU8t0t0jzzAXF1e2lMtofTXuzPjjI+5J6irRFXVLJSFFGRMyeG\nWP+xibTh3nJv+RloIvwzfJSEBMtAZixdFVakSEcCgYAGA2cZ3zRYOOwuBwuAISEb\nGXr7AxPSLL715S+ivPekOK5zMGm6IXj0H9zDopKM4u3VSnDFO7HzVqfJ0m3bPM7k\nLhGVi1abOInD6zrt7dFPcpBsLYZFvB6clv8zrwEQt2Pn7DVGGC9xRc7vv4aJ95C0\nXJ/ZUCRzpRLUawVYYvPxMQKBgByV6qVGwSPNLFo47GxXqOSaigJ6Id46pw3rd7+Y\n+JmciTP1w28FYWyRv0pP9UknkeeFVFuMFk+nbFo3cU+DkOmSo2wW5dmK+AF1GHAA\nbqL9IZuV8N8Y+OyHSxRTmze8K+0O5lG34LOl3VMGcUzQfTdCdJrW19phocRlNQP8\nk9hfAoGANvL/IXp5vUhpRbaBRx2GOe5/pDhHix2FDDMVYhsAXhpGW96KfipG8/sH\n6XBrfS/gDJ//q8LDLmxc23GQNPIMV7f+D2HIQav+AQwgicq63WaGXQP0Zv71xhiE\njT7DpdXWaJbzd/sqa+m9E/HJ1F57eCN13Pgrw6odZPR5D0y4A8o=\n-----END RSA PRIVATE KEY-----\n",
            "cluster_ca_certificate": "-----BEGIN CERTIFICATE-----\nMIIDBTCCAe2gAwIBAgIIeiJiGxyFobAwDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yNTAyMjQxMDM3MThaFw0zNTAyMjIxMDQyMThaMBUx\nEzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQDdv/7MNys9FG1K8ABD/NL0GNEfDBZCCeW4EeUxieytx0pyG8dNmzC88Fur\n+XpKh8EpV1z9frU59nAhUkybwEFoHepwkvoHiIWnH6G6pEXMXhvjlJ++pSrHGMHb\n2FPurVR/AAj1d+qGFXxvdGOqkWzNOy5zma40875YuR4+uLjFE1Rj1FQV0FZgSGnN\nfnOV/YMsWauybj6Z0arHSOdL7bWb654oXu1VRp5r/JR4Rx4PMWYaB6iYD/OA7s3W\nKY2DNipB5sWO1zh7uy/pyH60W43P7vafTGWRyzRThUyHFP5txJgfNHqOgYqXNcfE\nKvW1IKCh47TxyvBHDLxbp3ybeCHlAgMBAAGjWTBXMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBQ79M5RnfiYX5Ae61I2vTC+NYidXTAV\nBgNVHREEDjAMggprdWJlcm5ldGVzMA0GCSqGSIb3DQEBCwUAA4IBAQAEHnvH+JBo\ndFEE4SHhGkUZ+uNgm+EkyQNIYdNnpepEMc1krT4E1CUZqeSH1zKhIhZCdAfczp8O\nxPwoh6Jb48g+sTilV2t5xwgJrVl8qPL6Q7WYf8gsvOz9UhHMwzLe/+eCh2+6GKXR\nuObVt9aYNH0hVpBGUSgMmW/B41PqXhEPsoZ8ttFhVpuz8Zyj07LFrWilu7ZpK50/\nXlRuoE7V7lXO8VykK7NjMlA5or0J48Ik0u8QkXA0DpYnSu3zQu7APTxpTSi/1hVC\nKPE4l7+mhjZ7x187xvLBR4L+RWWT0NfqB3PbTsKtuoKtfM6hjjl1wSUYMcsWVepH\nimWbc1yxy+LQ\n-----END CERTIFICATE-----\n",
            "endpoint": "https://dev-1-control-plane:6443",
            "id": "dev-1-kindest/node:v1.29.0",
            "kind_config": "kind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nkubeadmConfigPatches:\n- |-\n  kind: ClusterConfiguration\n  # configure controller-manager bind address\n  controllerManager:\n    extraArgs:\n      bind-address: 0.0.0.0\n  # configure etcd metrics listen address\n  etcd:\n    local:\n      extraArgs:\n        listen-metrics-urls: http://0.0.0.0:2381\n  # configure scheduler bind address\n  scheduler:\n    extraArgs:\n      bind-address: 0.0.0.0\n- |-\n  kind: KubeProxyConfiguration\n  # configure proxy metrics bind address\n  metricsBindAddress: 0.0.0.0\nnodes:\n- role: control-plane\n- role: worker\n  labels:\n    ingress : worker\n  extraPortMappings:\n    - containerPort: 80\n      hostPort: 80\n      protocol: TCP\n    - containerPort: 443\n      hostPort: 443\n      protocol: TCP\n- role: worker\n- role: worker\n",
            "kubeconfig": "apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJZWlKaUd4eUZvYkF3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TlRBeU1qUXhNRE0zTVRoYUZ3MHpOVEF5TWpJeE1EUXlNVGhhTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUURkdi83TU55czlGRzFLOEFCRC9OTDBHTkVmREJaQ0NlVzRFZVV4aWV5dHgwcHlHOGRObXpDODhGdXIKK1hwS2g4RXBWMXo5ZnJVNTluQWhVa3lid0VGb0hlcHdrdm9IaUlXbkg2RzZwRVhNWGh2amxKKytwU3JIR01IYgoyRlB1clZSL0FBajFkK3FHRlh4dmRHT3FrV3pOT3k1em1hNDA4NzVZdVI0K3VMakZFMVJqMUZRVjBGWmdTR25OCmZuT1YvWU1zV2F1eWJqNlowYXJIU09kTDdiV2I2NTRvWHUxVlJwNXIvSlI0Ung0UE1XWWFCNmlZRC9PQTdzM1cKS1kyRE5pcEI1c1dPMXpoN3V5L3B5SDYwVzQzUDd2YWZUR1dSeXpSVGhVeUhGUDV0eEpnZk5IcU9nWXFYTmNmRQpLdlcxSUtDaDQ3VHh5dkJIREx4YnAzeWJlQ0hsQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJRNzlNNVJuZmlZWDVBZTYxSTJ2VEMrTllpZFhUQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQUVIbnZIK0pCbwpkRkVFNFNIaEdrVVordU5nbStFa3lRTklZZE5ucGVwRU1jMWtyVDRFMUNVWnFlU0gxektoSWhaQ2RBZmN6cDhPCnhQd29oNkpiNDhnK3NUaWxWMnQ1eHdnSnJWbDhxUEw2UTdXWWY4Z3N2T3o5VWhITXd6TGUvK2VDaDIrNkdLWFIKdU9iVnQ5YVlOSDBoVnBCR1VTZ01tVy9CNDFQcVhoRVBzb1o4dHRGaFZwdXo4WnlqMDdMRnJXaWx1N1pwSzUwLwpYbFJ1b0U3VjdsWE84VnlrSzdOak1sQTVvcjBKNDhJazB1OFFrWEEwRHBZblN1M3pRdTdBUFR4cFRTaS8xaFZDCktQRTRsNyttaGpaN3gxODd4dkxCUjRMK1JXV1QwTmZxQjNQYlRzS3R1b0t0Zk02aGpqbDF3U1VZTWNzV1ZlcEgKaW1XYmMxeXh5K0xRCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n    server: https://dev-1-control-plane:6443\n  name: kind-dev-1\ncontexts:\n- context:\n    cluster: kind-dev-1\n    user: kind-dev-1\n  name: kind-dev-1\ncurrent-context: kind-dev-1\nkind: Config\npreferences: {}\nusers:\n- name: kind-dev-1\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURLVENDQWhHZ0F3SUJBZ0lJRnIwNXhsS056YTB3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TlRBeU1qUXhNRE0zTVRoYUZ3MHlOakF5TWpReE1EUXlNVGxhTUR3eApIekFkQmdOVkJBb1RGbXQxWW1WaFpHMDZZMngxYzNSbGNpMWhaRzFwYm5NeEdUQVhCZ05WQkFNVEVHdDFZbVZ5CmJtVjBaWE10WVdSdGFXNHdnZ0VpTUEwR0NTcUdTSWIzRFFFQkFRVUFBNElCRHdBd2dnRUtBb0lCQVFESFBTbkYKcWNieG5WZnF3Z2JzeWk1bmFBTS90blM0aFdrS2VHTmZoVFZnZmZPa2dXdVM2VjJRZS9YdlVTNVdyS1hRVnFwRwpPaGljOG56dDZmTjRlWkZlT1VDY2dFbVFTRFNYRExrRzVmNU8vYU5TallGVk5xSWk1cU52RUhtVXpWNk5oZjBDCk5kT0JhY201THE3RG9vT1BzNUVLQkhzeTBESEJkVXlhRmE4b05sT0tFT1RwL3pQYWEwTVdGQ0hpZ01aTXFZSWcKRGhSQzltVXduUXdXT0M1MG9PWDBIUUNOSklQTjAxQzdJcVVHeldlS3M3blVreTdIbkNtRHNWZncweUd5UVhyVwpBUk5NMUxIcTF4OWJnczFTdTJVckNBUUF5aGFLWFlLT1ZWV2pjN2IrSEdEcmZoRVFWdUE2U1ZsZmhiREo4VXgvClF5TWZDRHlPU3ZGMjVNMS9BZ01CQUFHalZqQlVNQTRHQTFVZER3RUIvd1FFQXdJRm9EQVRCZ05WSFNVRUREQUsKQmdnckJnRUZCUWNEQWpBTUJnTlZIUk1CQWY4RUFqQUFNQjhHQTFVZEl3UVlNQmFBRkR2MHpsR2QrSmhma0I3cgpVamE5TUw0MWlKMWRNQTBHQ1NxR1NJYjNEUUVCQ3dVQUE0SUJBUUF2ZDlhby9qd0ZBbEpsNzRlTUhVVnFXNkk3CjJkMDRBWmhLdVY3MHhCZC9SaFVZZ2hFMDZOTXpmVzQxYWc0MXhrdzRCZHNQN2NIdjQ2WU1DZEpTbXptRjJHMHIKTE1LQmVKOFN4bFhLUzYzd2crMGRNcVdFLzFQVmNNSGluODJsT3NUdUx2OGZwSCtUbmFFL29zcHFNM1R2a2NIbgpydzR3dmdRZGt1YmJzUUx4dVVaU2dsdUlKTWRIOGZ2OFdnYTRjWXZvekJRUlRKMkh2d0hWcGFBY1E1bVVLTUdKClJUTldqVUVoT1VOclZjRjZBZWx0ZkVrcTFKSEs1KzExdyt1R2VRT3NyQjJrZXIyT2V5Q09CVzlrSjloZWM4UnUKd2M1dDlEdFRmOXRhQUV0SXM1eUxPdVFEWmpyWlFxUktodmpObnZINXJJSEIvUmJUTHBFNWV5VFlHOW02Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n    client-key-data: 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\n",
            "kubeconfig_path": "/Users/mkoellges/repos/github/mkoellges/kind/terraform/dev-1-config",
            "name": "dev-1",
            "node_image": "kindest/node:v1.29.0",
            "timeouts": null,
            "wait_for_ready": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjozMDAwMDAwMDAwMDAsImRlbGV0ZSI6MzAwMDAwMDAwMDAwLCJ1cGRhdGUiOjMwMDAwMDAwMDAwMH19"
        }
      ]
    }
  ],
  "check_results": null
}
